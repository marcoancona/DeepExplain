{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DeepExplain - Keras (TF backend) example\n",
    "### MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tempfile, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "# Import DeepExplain\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "\n",
    "#Import DeepLift\n",
    "import deeplift\n",
    "from deeplift.layers import NonlinearMxtsMode\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "from deeplift.util import compile_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:16: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:17: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 16)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.2561 - acc: 0.5818 - val_loss: 0.8332 - val_acc: 0.7337\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.7301 - acc: 0.7630 - val_loss: 0.6372 - val_acc: 0.7940\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.6167 - acc: 0.7987 - val_loss: 0.6131 - val_acc: 0.7958\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.5584 - acc: 0.8160 - val_loss: 0.5363 - val_acc: 0.8212\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.5222 - acc: 0.8293 - val_loss: 0.4990 - val_acc: 0.8352\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.4897 - acc: 0.8397 - val_loss: 0.4605 - val_acc: 0.8503\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4689 - acc: 0.8469 - val_loss: 0.4591 - val_acc: 0.8521\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4482 - acc: 0.8526 - val_loss: 0.4392 - val_acc: 0.8522\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.4335 - acc: 0.8569 - val_loss: 0.4309 - val_acc: 0.8595\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.4191 - acc: 0.8625 - val_loss: 0.4177 - val_acc: 0.8674\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4077 - acc: 0.8665 - val_loss: 0.4073 - val_acc: 0.8682\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3958 - acc: 0.8700 - val_loss: 0.3927 - val_acc: 0.8718\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3881 - acc: 0.8715 - val_loss: 0.4198 - val_acc: 0.8633\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3790 - acc: 0.8750 - val_loss: 0.3715 - val_acc: 0.8805\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3709 - acc: 0.8782 - val_loss: 0.3572 - val_acc: 0.8841\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3645 - acc: 0.8794 - val_loss: 0.3504 - val_acc: 0.8853\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.3565 - acc: 0.8822 - val_loss: 0.3616 - val_acc: 0.8810\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3527 - acc: 0.8833 - val_loss: 0.3992 - val_acc: 0.8648\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3483 - acc: 0.8848 - val_loss: 0.3601 - val_acc: 0.8813\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3429 - acc: 0.8869 - val_loss: 0.3300 - val_acc: 0.8957\n",
      "0.0036148468\n",
      "0.05318696\n"
     ]
    }
   ],
   "source": [
    "# Build and train a network.\n",
    "\n",
    "SKIP_TRAIN = False\n",
    "saved_model_file = 'model.h5'\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 4, 4\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.array([scipy.misc.imresize(x, (img_rows,img_cols,)) for x in x_train])\n",
    "x_test = np.array([scipy.misc.imresize(x, (img_rows,img_cols,)) for x in x_test])\n",
    "\n",
    "\n",
    "\n",
    "#x_train = x_train.reshape(-1, 28,28,1)\n",
    "#x_test = x_test.reshape(-1, 28,28,1)\n",
    "x_train = x_train.reshape(-1, img_rows*img_cols)\n",
    "x_test = x_test.reshape(-1, img_rows*img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train = (x_train - 0.5) * 2\n",
    "x_test = (x_test - 0.5) * 2\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "\n",
    "def f(x):\n",
    "    return x*tf.sigmoid(x)\n",
    "\n",
    "if SKIP_TRAIN:\n",
    "    model = load_model(saved_model_file)\n",
    "else:\n",
    "    #de.enable_override('shapley')\n",
    "    model = Sequential()\n",
    "    #model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(128, input_shape=(img_rows*img_cols,), activation='relu', kernel_regularizer=regularizers.l1(0.000)))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.000)))       \n",
    "    model.add(Dense(num_classes, kernel_regularizer=regularizers.l1(0.00)))\n",
    "    model.add(Activation('softmax'))\n",
    "    # ^ IMPORTANT: notice that the final softmax must be in its own layer \n",
    "    # if we want to target pre-softmax units\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    model.save(saved_model_file)\n",
    "    print (model.layers[0].get_weights()[0].mean())\n",
    "    print (model.layers[0].get_weights()[0].var())\n",
    "    \n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.73541e+05, 3.06760e+04, 3.21960e+04, 3.33480e+04, 3.46130e+04,\n",
       "        3.55280e+04, 3.55440e+04, 3.44980e+04, 3.37880e+04, 3.25320e+04,\n",
       "        3.14430e+04, 3.02900e+04, 2.89010e+04, 2.69100e+04, 2.56230e+04,\n",
       "        2.34560e+04, 2.19220e+04, 2.02290e+04, 1.85850e+04, 1.72660e+04,\n",
       "        1.58600e+04, 1.45500e+04, 1.31300e+04, 1.21230e+04, 1.09020e+04,\n",
       "        1.00380e+04, 8.91100e+03, 8.07500e+03, 7.29900e+03, 6.66300e+03,\n",
       "        5.75700e+03, 5.39500e+03, 4.75900e+03, 4.18100e+03, 3.89100e+03,\n",
       "        3.27400e+03, 2.88500e+03, 2.57900e+03, 2.21700e+03, 1.95200e+03,\n",
       "        1.78200e+03, 1.53000e+03, 1.38500e+03, 1.22700e+03, 1.03500e+03,\n",
       "        9.19000e+02, 8.27000e+02, 7.42000e+02, 6.14000e+02, 5.62000e+02,\n",
       "        4.87000e+02, 4.48000e+02, 3.97000e+02, 3.72000e+02, 3.20000e+02,\n",
       "        2.67000e+02, 2.20000e+02, 2.29000e+02, 1.76000e+02, 1.43000e+02,\n",
       "        1.34000e+02, 1.13000e+02, 1.12000e+02, 8.90000e+01, 8.20000e+01,\n",
       "        6.50000e+01, 6.10000e+01, 3.20000e+01, 4.50000e+01, 3.70000e+01,\n",
       "        2.90000e+01, 3.20000e+01, 2.70000e+01, 3.10000e+01, 1.90000e+01,\n",
       "        1.90000e+01, 1.10000e+01, 9.00000e+00, 6.00000e+00, 6.00000e+00,\n",
       "        4.00000e+00, 8.00000e+00, 5.00000e+00, 3.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 1.00000e+00, 1.00000e+00, 3.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([0.        , 0.01554611, 0.03109221, 0.04663832, 0.06218442,\n",
       "        0.07773053, 0.09327664, 0.10882274, 0.12436885, 0.13991495,\n",
       "        0.15546106, 0.17100717, 0.18655327, 0.20209938, 0.21764549,\n",
       "        0.23319159, 0.2487377 , 0.2642838 , 0.27982991, 0.29537602,\n",
       "        0.31092212, 0.32646823, 0.34201433, 0.35756044, 0.37310655,\n",
       "        0.38865265, 0.40419876, 0.41974486, 0.43529097, 0.45083708,\n",
       "        0.46638318, 0.48192929, 0.4974754 , 0.5130215 , 0.52856761,\n",
       "        0.54411371, 0.55965982, 0.57520593, 0.59075203, 0.60629814,\n",
       "        0.62184424, 0.63739035, 0.65293646, 0.66848256, 0.68402867,\n",
       "        0.69957477, 0.71512088, 0.73066699, 0.74621309, 0.7617592 ,\n",
       "        0.77730531, 0.79285141, 0.80839752, 0.82394362, 0.83948973,\n",
       "        0.85503584, 0.87058194, 0.88612805, 0.90167415, 0.91722026,\n",
       "        0.93276637, 0.94831247, 0.96385858, 0.97940468, 0.99495079,\n",
       "        1.0104969 , 1.026043  , 1.04158911, 1.05713521, 1.07268132,\n",
       "        1.08822743, 1.10377353, 1.11931964, 1.13486575, 1.15041185,\n",
       "        1.16595796, 1.18150406, 1.19705017, 1.21259628, 1.22814238,\n",
       "        1.24368849, 1.25923459, 1.2747807 , 1.29032681, 1.30587291,\n",
       "        1.32141902, 1.33696512, 1.35251123, 1.36805734, 1.38360344,\n",
       "        1.39914955, 1.41469566, 1.43024176, 1.44578787, 1.46133397,\n",
       "        1.47688008, 1.49242619, 1.50797229, 1.5235184 , 1.5390645 ,\n",
       "        1.55461061]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npG6GhiSpm6EhSepmaEiSuv0/oGMvQLuUTWgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf332b6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "aModel = Model(inputs=model.inputs, outputs=[model.layers[1].input])\n",
    "y = aModel.predict(x_test)\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.hist(model.layers[1].get_weights()[0].flatten(), 100)\n",
    "plt.hist(y.flatten(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define what to be explained\n",
    "xs = x_test[1:2]\n",
    "ys = y_test[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: RevealCancel\n",
      "Heads-up: I assume softmax is the output layer, not an intermediate one; if it's an intermediate layer, please let me know and I will prioritise that use-case\n",
      "nonlinear_mxts_mode is set to: Rescale\n",
      "Heads-up: I assume softmax is the output layer, not an intermediate one; if it's an intermediate layer, please let me know and I will prioritise that use-case\n"
     ]
    }
   ],
   "source": [
    "# Compute DeepLift attributions\n",
    "revealcancel_model = kc.convert_model_from_saved_files(\n",
    "                            h5_file=saved_model_file,\n",
    "                            nonlinear_mxts_mode=NonlinearMxtsMode.RevealCancel)\n",
    "rescale_model = kc.convert_model_from_saved_files(\n",
    "                            h5_file=saved_model_file,\n",
    "                            nonlinear_mxts_mode=NonlinearMxtsMode.Rescale)\n",
    "\n",
    "revealcancel_func = revealcancel_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "rescale_func = rescale_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "\n",
    "a_rc = np.array(revealcancel_func(\n",
    "                task_idx=np.argmax(ys),\n",
    "                input_data_list=[xs],\n",
    "                input_references_list=[np.zeros_like(xs)],\n",
    "                batch_size=100,\n",
    "                progress_update=None))\n",
    "\n",
    "a_res = np.array(rescale_func(\n",
    "                task_idx=np.argmax(ys),\n",
    "                input_data_list=[xs],\n",
    "                input_references_list=[np.zeros_like(xs)],\n",
    "                batch_size=100,\n",
    "                progress_update=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 11.2 Âµs\n",
      "{'Sigmoid': 'DeepExplainGrad', 'Softplus': 'DeepExplainGrad', 'MatMul': 'MatMulDeepExplainGrad', 'Tanh': 'DeepExplainGrad', 'Elu': 'DeepExplainGrad', 'Relu': 'DeepExplainGrad'}\n",
      "DeepExplain: running \"grad*input\" explanation method (2)\n",
      "Model with multiple inputs:  False\n",
      "DeepExplain: running \"intgrad\" explanation method (3)\n",
      "Model with multiple inputs:  False\n",
      "DeepExplain: running \"linear\" explanation method (7)\n",
      "Model with multiple inputs:  False\n",
      "Shapley: computing references...\n",
      "model_2/dense_2/MatMul_x (1, 128)\n",
      "model_2/dense_1/MatMul_w (16, 128)\n",
      "model_3/dense_1/MatMul_b (128,)\n",
      "model_2/dense_3/MatMul_x (1, 128)\n",
      "model_2/dense_2/MatMul_b (128,)\n",
      "model_2/dense_3/MatMul_b (10,)\n",
      "model_2/dense_1/MatMul_b (128,)\n",
      "model_3/dense_3/MatMul_b (10,)\n",
      "model_2/dense_1/MatMul_x (1, 16)\n",
      "model_3/dense_1/MatMul_w (16, 128)\n",
      "model_3/dense_2/MatMul_w (128, 128)\n",
      "model_3/dense_2/MatMul_b (128,)\n",
      "model_3/dense_3/MatMul_w (128, 10)\n",
      "model_3/dense_2/MatMul_x (1, 128)\n",
      "model_3/dense_1/MatMul_x (1, 16)\n",
      "model_2/dense_2/MatMul_w (128, 128)\n",
      "model_3/dense_3/MatMul_x (1, 128)\n",
      "model_2/dense_3/MatMul_w (128, 10)\n",
      "Shapley: references ready\n",
      "(1, 128)\n",
      "(128, 10)\n",
      "(10,)\n",
      "(1, 128)\n",
      "Skip dense_3\n",
      "(1, 128)\n",
      "(128, 128)\n",
      "(128,)\n",
      "(1, 128)\n",
      "Mean:  0.011347102\n",
      "Var:  0.002044505\n",
      "Bias:  -0.057858586\n",
      "Input:  1.3945705\n",
      "Mean:  -0.0027440835\n",
      "Var:  0.00038091207\n",
      "Bias:  0.0\n",
      "Input:  -0.3512427\n",
      "Mean:  0.006783667\n",
      "Var:  0.0013703178\n",
      "Bias:  -0.08044167\n",
      "Input:  0.7878677\n",
      "Mean:  -0.0076357424\n",
      "Var:  0.0027246526\n",
      "Bias:  0.011946435\n",
      "Input:  -0.9654286\n",
      "Mean:  -0.0018049118\n",
      "Var:  0.0021731497\n",
      "Bias:  -0.008518126\n",
      "Input:  -0.23954684\n",
      "Mean:  0.02878411\n",
      "Var:  0.0069349175\n",
      "Bias:  0.14418365\n",
      "Input:  3.8285496\n",
      "Mean:  -0.018207602\n",
      "Var:  0.005070991\n",
      "Bias:  -0.06340704\n",
      "Input:  -2.39398\n",
      "Mean:  -0.007802947\n",
      "Var:  0.0033997286\n",
      "Bias:  -0.014046046\n",
      "Input:  -1.0128232\n",
      "Mean:  0.007560541\n",
      "Var:  0.0012698038\n",
      "Bias:  -0.06695735\n",
      "Input:  0.9007919\n",
      "Mean:  0.014900644\n",
      "Var:  0.0048623052\n",
      "Bias:  0.1827435\n",
      "Input:  2.090026\n",
      "Mean:  -0.0005403267\n",
      "Var:  0.00056812435\n",
      "Bias:  0.010533356\n",
      "Input:  -0.058628462\n",
      "Mean:  -0.0020468705\n",
      "Var:  0.0025475707\n",
      "Bias:  0.11046493\n",
      "Input:  -0.1515345\n",
      "Mean:  0.020095265\n",
      "Var:  0.004969259\n",
      "Bias:  0.2826237\n",
      "Input:  2.8548176\n",
      "Mean:  0.012464081\n",
      "Var:  0.003786855\n",
      "Bias:  -0.08484463\n",
      "Input:  1.5105578\n",
      "Mean:  0.0045605246\n",
      "Var:  0.001187348\n",
      "Bias:  0.07330768\n",
      "Input:  0.65705484\n",
      "Mean:  0.0025872742\n",
      "Var:  0.00357093\n",
      "Bias:  -0.04518252\n",
      "Input:  0.28598857\n",
      "Mean:  -0.018242517\n",
      "Var:  0.0058438852\n",
      "Bias:  -0.060115118\n",
      "Input:  -2.3951573\n",
      "Mean:  -0.008462431\n",
      "Var:  0.004352161\n",
      "Bias:  -0.07350688\n",
      "Input:  -1.156698\n",
      "Mean:  0.008055729\n",
      "Var:  0.0027454915\n",
      "Bias:  0.110496394\n",
      "Input:  1.1416297\n",
      "Mean:  0.0013079657\n",
      "Var:  0.0032352745\n",
      "Bias:  -0.063870005\n",
      "Input:  0.10354961\n",
      "Mean:  -0.012958445\n",
      "Var:  0.0031699936\n",
      "Bias:  -0.010323454\n",
      "Input:  -1.6690043\n",
      "Mean:  0.009416604\n",
      "Var:  0.002329126\n",
      "Bias:  0.073357\n",
      "Input:  1.2786824\n",
      "Mean:  -0.014199053\n",
      "Var:  0.0052994457\n",
      "Bias:  0.20601793\n",
      "Input:  -1.6114608\n",
      "Mean:  0.01437614\n",
      "Var:  0.003313893\n",
      "Bias:  0.053296167\n",
      "Input:  1.8934422\n",
      "Mean:  -0.0006571433\n",
      "Var:  0.0033544316\n",
      "Bias:  -0.083972074\n",
      "Input:  -0.16808641\n",
      "Mean:  -0.0044870754\n",
      "Var:  0.002427755\n",
      "Bias:  0.078208014\n",
      "Input:  -0.49613762\n",
      "Mean:  0.0032277284\n",
      "Var:  0.0025634882\n",
      "Bias:  -0.0531924\n",
      "Input:  0.35995683\n",
      "Mean:  0.0035879165\n",
      "Var:  0.003916147\n",
      "Bias:  -0.0060260515\n",
      "Input:  0.45322725\n",
      "Mean:  -0.0017768149\n",
      "Var:  0.000357024\n",
      "Bias:  -0.04493023\n",
      "Input:  -0.27236253\n",
      "Mean:  -0.0042250045\n",
      "Var:  0.0027701582\n",
      "Bias:  0.11841779\n",
      "Input:  -0.42238277\n",
      "Mean:  0.0037292007\n",
      "Var:  0.0033984627\n",
      "Bias:  0.097436085\n",
      "Input:  0.5747738\n",
      "Mean:  -0.0016577889\n",
      "Var:  0.0020718565\n",
      "Bias:  -0.074442305\n",
      "Input:  -0.28663927\n",
      "Mean:  0.005355318\n",
      "Var:  0.002014954\n",
      "Bias:  0.21326208\n",
      "Input:  0.8987428\n",
      "Mean:  0.011412114\n",
      "Var:  0.005960134\n",
      "Bias:  -0.010247336\n",
      "Input:  1.4505032\n",
      "Mean:  -0.022162456\n",
      "Var:  0.0062940903\n",
      "Bias:  -0.027724274\n",
      "Input:  -2.8645186\n",
      "Mean:  0.004601187\n",
      "Var:  0.001979902\n",
      "Bias:  -0.074137434\n",
      "Input:  0.5148145\n",
      "Mean:  -0.0014360728\n",
      "Var:  0.0016733891\n",
      "Bias:  -0.06604534\n",
      "Input:  -0.24986264\n",
      "Mean:  -0.023141244\n",
      "Var:  0.007002432\n",
      "Bias:  0.061433025\n",
      "Input:  -2.9006462\n",
      "Mean:  0.0011208667\n",
      "Var:  0.0025114259\n",
      "Bias:  0.12644745\n",
      "Input:  0.26991838\n",
      "Mean:  -0.011140796\n",
      "Var:  0.0036167041\n",
      "Bias:  -0.056290247\n",
      "Input:  -1.4823122\n",
      "Mean:  -0.004284686\n",
      "Var:  0.00059515645\n",
      "Bias:  -0.08166838\n",
      "Input:  -0.6301082\n",
      "Mean:  0.014752476\n",
      "Var:  0.0048077162\n",
      "Bias:  0.16548854\n",
      "Input:  2.0538054\n",
      "Mean:  -0.013579102\n",
      "Var:  0.0038030348\n",
      "Bias:  -0.054292087\n",
      "Input:  -1.7924172\n",
      "Mean:  0.004033018\n",
      "Var:  0.0028418466\n",
      "Bias:  0.040864024\n",
      "Input:  0.55709034\n",
      "Mean:  0.005172055\n",
      "Var:  0.0015163156\n",
      "Bias:  0.16210227\n",
      "Input:  0.82412535\n",
      "Mean:  0.0031937757\n",
      "Var:  0.001331347\n",
      "Bias:  0.04204441\n",
      "Input:  0.4508477\n",
      "Mean:  0.016185801\n",
      "Var:  0.004558871\n",
      "Bias:  0.1810344\n",
      "Input:  2.252817\n",
      "Mean:  -0.0013888697\n",
      "Var:  0.00052037096\n",
      "Bias:  -0.02109085\n",
      "Input:  -0.19886617\n",
      "Mean:  0.018134087\n",
      "Var:  0.004357828\n",
      "Bias:  0.076880425\n",
      "Input:  2.3980436\n",
      "Mean:  -0.009934277\n",
      "Var:  0.0013631836\n",
      "Bias:  0.0046670935\n",
      "Input:  -1.2669204\n",
      "Mean:  0.00071967323\n",
      "Var:  0.0030298715\n",
      "Bias:  0.013865315\n",
      "Input:  0.10598349\n",
      "Mean:  0.009946028\n",
      "Var:  0.0043306295\n",
      "Bias:  0.062102832\n",
      "Input:  1.3351943\n",
      "Mean:  -0.01128045\n",
      "Var:  0.0031987745\n",
      "Bias:  0.13057958\n",
      "Input:  -1.313318\n",
      "Mean:  0.0080694165\n",
      "Var:  0.00306089\n",
      "Bias:  -0.06205091\n",
      "Input:  0.9708344\n",
      "Mean:  -0.0077284807\n",
      "Var:  0.002762992\n",
      "Bias:  -0.12844206\n",
      "Input:  -1.1176876\n",
      "Mean:  0.0135363545\n",
      "Var:  0.002425472\n",
      "Bias:  -0.051283363\n",
      "Input:  1.68137\n",
      "Mean:  -0.0020921724\n",
      "Var:  0.00038952322\n",
      "Bias:  0.010033392\n",
      "Input:  -0.25776467\n",
      "Mean:  0.009838015\n",
      "Var:  0.00419147\n",
      "Bias:  0.10333439\n",
      "Input:  1.3626003\n",
      "Mean:  0.0059659006\n",
      "Var:  0.0014737882\n",
      "Bias:  0.07112985\n",
      "Input:  0.83476514\n",
      "Mean:  -0.009587465\n",
      "Var:  0.0048127715\n",
      "Bias:  0.035214722\n",
      "Input:  -1.1919808\n",
      "Mean:  -0.02036456\n",
      "Var:  0.006132948\n",
      "Bias:  -0.0378927\n",
      "Input:  -2.6445565\n",
      "Mean:  -0.00084108824\n",
      "Var:  0.0013093741\n",
      "Bias:  0.099981636\n",
      "Input:  -0.0076776594\n",
      "Mean:  -0.001123351\n",
      "Var:  0.0015181669\n",
      "Bias:  0.10922885\n",
      "Input:  -0.034560084\n",
      "Mean:  -0.0016171458\n",
      "Var:  0.00045021868\n",
      "Bias:  -0.01615183\n",
      "Input:  -0.2231465\n",
      "Mean:  0.012950383\n",
      "Var:  0.0026133358\n",
      "Bias:  0.10186917\n",
      "Input:  1.7595183\n",
      "Mean:  0.013839252\n",
      "Var:  0.0029581978\n",
      "Bias:  -0.094438694\n",
      "Input:  1.6769856\n",
      "Mean:  0.013980458\n",
      "Var:  0.001753648\n",
      "Bias:  -0.061448555\n",
      "Input:  1.72805\n",
      "Mean:  0.008770386\n",
      "Var:  0.0021292458\n",
      "Bias:  0.11301957\n",
      "Input:  1.235629\n",
      "Mean:  -0.0037207077\n",
      "Var:  0.0005308484\n",
      "Bias:  -0.014963649\n",
      "Input:  -0.49121425\n",
      "Mean:  0.01877912\n",
      "Var:  0.0054484634\n",
      "Bias:  0.020704098\n",
      "Input:  2.4244313\n",
      "Mean:  -0.004971165\n",
      "Var:  0.004060363\n",
      "Bias:  0.1338124\n",
      "Input:  -0.5024967\n",
      "Mean:  0.014396446\n",
      "Var:  0.0022530355\n",
      "Bias:  -0.042609636\n",
      "Input:  1.8001354\n",
      "Mean:  0.017807689\n",
      "Var:  0.0033508644\n",
      "Bias:  0.0026638713\n",
      "Input:  2.282048\n",
      "Mean:  0.014265787\n",
      "Var:  0.004212893\n",
      "Bias:  0.28011876\n",
      "Input:  2.1061394\n",
      "Mean:  -0.010280991\n",
      "Var:  0.0031043794\n",
      "Bias:  -0.058580097\n",
      "Input:  -1.3745469\n",
      "Mean:  0.0018805009\n",
      "Var:  0.0022648503\n",
      "Bias:  -0.044033382\n",
      "Input:  0.19667074\n",
      "Mean:  -0.00060295034\n",
      "Var:  0.00051680463\n",
      "Bias:  -0.010452749\n",
      "Input:  -0.08763039\n",
      "Mean:  -0.006375627\n",
      "Var:  0.0019991333\n",
      "Bias:  -0.0293275\n",
      "Input:  -0.8454078\n",
      "Mean:  -0.006518529\n",
      "Var:  0.002784454\n",
      "Bias:  -0.1167312\n",
      "Input:  -0.95110285\n",
      "Mean:  0.0051587913\n",
      "Var:  0.0033924123\n",
      "Bias:  0.13684025\n",
      "Input:  0.7971655\n",
      "Mean:  -0.0037034252\n",
      "Var:  0.00082754425\n",
      "Bias:  0.005985653\n",
      "Input:  -0.46805277\n",
      "Mean:  -0.005056395\n",
      "Var:  0.0034303605\n",
      "Bias:  0.11067539\n",
      "Input:  -0.5365432\n",
      "Mean:  0.008988566\n",
      "Var:  0.0035095725\n",
      "Bias:  0.18436782\n",
      "Input:  1.3349042\n",
      "Mean:  0.010761239\n",
      "Var:  0.0018790285\n",
      "Bias:  -0.06153365\n",
      "Input:  1.3159049\n",
      "Mean:  0.008843625\n",
      "Var:  0.0041596997\n",
      "Bias:  -0.046093415\n",
      "Input:  1.0858905\n",
      "Mean:  -0.0019998564\n",
      "Var:  0.00045580723\n",
      "Bias:  -0.042268824\n",
      "Input:  -0.29825044\n",
      "Mean:  0.0066497256\n",
      "Var:  0.0012373992\n",
      "Bias:  0.17100836\n",
      "Input:  1.0221733\n",
      "Mean:  -0.0014840385\n",
      "Var:  0.0005119505\n",
      "Bias:  -0.008459542\n",
      "Input:  -0.19841647\n",
      "Mean:  -0.010834285\n",
      "Var:  0.0020819844\n",
      "Bias:  0.12188793\n",
      "Input:  -1.2649006\n",
      "Mean:  0.0036681257\n",
      "Var:  0.0018692568\n",
      "Bias:  0.040011823\n",
      "Input:  0.5095319\n",
      "Mean:  -0.004375826\n",
      "Var:  0.0005033009\n",
      "Bias:  -0.022652758\n",
      "Input:  -0.5827585\n",
      "Mean:  -0.003207646\n",
      "Var:  0.0040509757\n",
      "Bias:  -0.07870487\n",
      "Input:  -0.48928356\n",
      "Mean:  -0.0023280298\n",
      "Var:  0.00043828358\n",
      "Bias:  -0.023336343\n",
      "Input:  -0.32132417\n",
      "Mean:  -0.006392937\n",
      "Var:  0.0047772992\n",
      "Bias:  -0.06126035\n",
      "Input:  -0.8795563\n",
      "Mean:  -0.009224819\n",
      "Var:  0.0033913078\n",
      "Bias:  0.04733586\n",
      "Input:  -1.133441\n",
      "Mean:  -0.004471449\n",
      "Var:  0.00039253212\n",
      "Bias:  -5.4145396e-05\n",
      "Input:  -0.5723996\n",
      "Mean:  0.00021130824\n",
      "Var:  0.004482312\n",
      "Bias:  0.07998488\n",
      "Input:  0.10703234\n",
      "Mean:  -0.0023136514\n",
      "Var:  0.0032157702\n",
      "Bias:  0.07106902\n",
      "Input:  -0.22507836\n",
      "Mean:  0.0075466754\n",
      "Var:  0.0017920546\n",
      "Bias:  0.06043553\n",
      "Input:  1.02641\n",
      "Mean:  0.012942668\n",
      "Var:  0.0026485762\n",
      "Bias:  0.074772075\n",
      "Input:  1.7314336\n",
      "Mean:  -0.0072433874\n",
      "Var:  0.0048182\n",
      "Bias:  0.15913257\n",
      "Input:  -0.768021\n",
      "Mean:  0.0055991146\n",
      "Var:  0.0029588402\n",
      "Bias:  0.0143001145\n",
      "Input:  0.7309868\n",
      "Mean:  0.004727384\n",
      "Var:  0.0014897508\n",
      "Bias:  0.01024559\n",
      "Input:  0.6153507\n",
      "Mean:  -0.010084579\n",
      "Var:  0.0044356077\n",
      "Bias:  0.06481828\n",
      "Input:  -1.2260078\n",
      "Mean:  0.007265438\n",
      "Var:  0.0026497669\n",
      "Bias:  -0.11149632\n",
      "Input:  0.8184797\n",
      "Mean:  0.008260281\n",
      "Var:  0.0024395096\n",
      "Bias:  -0.045107655\n",
      "Input:  1.0122083\n",
      "Mean:  -0.015969202\n",
      "Var:  0.004245421\n",
      "Bias:  0.04760345\n",
      "Input:  -1.9964544\n",
      "Mean:  -0.0013634536\n",
      "Var:  0.0004054772\n",
      "Bias:  -0.04133164\n",
      "Input:  -0.21585369\n",
      "Mean:  -0.005568689\n",
      "Var:  0.003102501\n",
      "Bias:  0.06800593\n",
      "Input:  -0.6447863\n",
      "Mean:  0.0019831553\n",
      "Var:  0.002486635\n",
      "Bias:  -0.18760405\n",
      "Input:  0.06623982\n",
      "Mean:  -0.0052884454\n",
      "Var:  0.0028881761\n",
      "Bias:  -0.13458739\n",
      "Input:  -0.8115084\n",
      "Mean:  -0.011340996\n",
      "Var:  0.0045238873\n",
      "Bias:  0.16149023\n",
      "Input:  -1.2901573\n",
      "Mean:  -0.0037796125\n",
      "Var:  0.0022559864\n",
      "Bias:  0.062965706\n",
      "Input:  -0.4208247\n",
      "Mean:  -0.008522403\n",
      "Var:  0.0019667961\n",
      "Bias:  0.023896977\n",
      "Input:  -1.0669707\n",
      "Mean:  -0.014894748\n",
      "Var:  0.0056423056\n",
      "Bias:  0.09446706\n",
      "Input:  -1.8120607\n",
      "Mean:  0.0073873284\n",
      "Var:  0.0021463057\n",
      "Bias:  -0.013912526\n",
      "Input:  0.93166554\n",
      "Mean:  -0.003345368\n",
      "Var:  0.00055792625\n",
      "Bias:  0.0\n",
      "Input:  -0.4282071\n",
      "Mean:  -0.0019394034\n",
      "Var:  0.0007200696\n",
      "Bias:  -0.014310414\n",
      "Input:  -0.26255405\n",
      "Mean:  0.00036848523\n",
      "Var:  0.0005399763\n",
      "Bias:  0.009461048\n",
      "Input:  0.056627158\n",
      "Mean:  -0.008754725\n",
      "Var:  0.002680283\n",
      "Bias:  0.026054017\n",
      "Input:  -1.0945507\n",
      "Mean:  0.001360758\n",
      "Var:  0.0019361224\n",
      "Bias:  0.17024347\n",
      "Input:  0.3444205\n",
      "Mean:  0.0069666263\n",
      "Var:  0.0026322652\n",
      "Bias:  0.06561508\n",
      "Input:  0.9573432\n",
      "Mean:  -0.003078593\n",
      "Var:  0.00047612947\n",
      "Bias:  -0.012527016\n",
      "Input:  -0.40658692\n",
      "Mean:  0.030859694\n",
      "Var:  0.0066914554\n",
      "Bias:  0.03295737\n",
      "Input:  3.9829981\n",
      "Mean:  0.00639741\n",
      "Var:  0.003548684\n",
      "Bias:  0.052794017\n",
      "Input:  0.8716625\n",
      "Mean:  0.009755712\n",
      "Var:  0.0017100084\n",
      "Bias:  -0.06931771\n",
      "Input:  1.1794134\n",
      "Mean:  -0.013566315\n",
      "Var:  0.0069552083\n",
      "Bias:  0.049638025\n",
      "Input:  -1.6868503\n",
      "Mean:  0.0037294708\n",
      "Var:  0.0022464965\n",
      "Bias:  -0.0385133\n",
      "Input:  0.43885896\n",
      "(1, 16)\n",
      "(16, 128)\n",
      "(128,)\n",
      "(1, 16)\n",
      "Mean:  -0.0004906766\n",
      "Var:  0.026113674\n",
      "Bias:  -0.076982155\n",
      "Input:  -0.08483298\n",
      "Mean:  -0.043630138\n",
      "Var:  0.007243596\n",
      "Bias:  0.0\n",
      "Input:  -0.6980822\n",
      "Mean:  -0.01027857\n",
      "Var:  0.0132513\n",
      "Bias:  -0.05754864\n",
      "Input:  -0.22200575\n",
      "Mean:  -0.0031130323\n",
      "Var:  0.024773164\n",
      "Bias:  0.043527618\n",
      "Input:  -0.006280899\n",
      "Mean:  0.0031508617\n",
      "Var:  0.03286521\n",
      "Bias:  -0.18868592\n",
      "Input:  -0.13827214\n",
      "Mean:  -0.021275777\n",
      "Var:  0.013051255\n",
      "Bias:  0.038241737\n",
      "Input:  -0.3021707\n",
      "Mean:  0.01234559\n",
      "Var:  0.030587584\n",
      "Bias:  -0.010585431\n",
      "Input:  0.18694401\n",
      "Mean:  -0.014496789\n",
      "Var:  0.0066470504\n",
      "Bias:  -0.00014574901\n",
      "Input:  -0.23209438\n",
      "Mean:  -0.0013445355\n",
      "Var:  0.03195165\n",
      "Bias:  0.20120196\n",
      "Input:  0.17968939\n",
      "Mean:  0.018204957\n",
      "Var:  0.0377394\n",
      "Bias:  -0.120139174\n",
      "Input:  0.17114013\n",
      "Mean:  -0.008510575\n",
      "Var:  0.02949888\n",
      "Bias:  0.010542459\n",
      "Input:  -0.12562674\n",
      "Mean:  -0.02458503\n",
      "Var:  0.008482041\n",
      "Bias:  -0.0139995655\n",
      "Input:  -0.40736002\n",
      "Mean:  0.004353122\n",
      "Var:  0.033123724\n",
      "Bias:  -0.15204836\n",
      "Input:  -0.082398415\n",
      "Mean:  -0.0070926584\n",
      "Var:  0.016729632\n",
      "Bias:  0.05926239\n",
      "Input:  -0.054220144\n",
      "Mean:  0.027616724\n",
      "Var:  0.037887182\n",
      "Bias:  0.023430444\n",
      "Input:  0.46529803\n",
      "Mean:  0.012293656\n",
      "Var:  0.019318536\n",
      "Bias:  -0.038677014\n",
      "Input:  0.15802148\n",
      "Mean:  0.025499046\n",
      "Var:  0.021428887\n",
      "Bias:  -0.020544445\n",
      "Input:  0.3874403\n",
      "Mean:  0.014407516\n",
      "Var:  0.017212639\n",
      "Bias:  -0.05690784\n",
      "Input:  0.17361242\n",
      "Mean:  -0.017941533\n",
      "Var:  0.01818349\n",
      "Bias:  -0.062791444\n",
      "Input:  -0.34985596\n",
      "Mean:  0.00842326\n",
      "Var:  0.028894626\n",
      "Bias:  0.13964148\n",
      "Input:  0.27441365\n",
      "Mean:  0.006032627\n",
      "Var:  0.018160636\n",
      "Bias:  -0.024069691\n",
      "Input:  0.072452344\n",
      "Mean:  0.00827181\n",
      "Var:  0.022823744\n",
      "Bias:  0.006423234\n",
      "Input:  0.13877219\n",
      "Mean:  0.023923818\n",
      "Var:  0.020207487\n",
      "Bias:  -0.22876215\n",
      "Input:  0.15401894\n",
      "Mean:  -0.0065933475\n",
      "Var:  0.036816604\n",
      "Bias:  0.2250592\n",
      "Input:  0.119565636\n",
      "Mean:  0.029974744\n",
      "Var:  0.022458034\n",
      "Bias:  -0.18546417\n",
      "Input:  0.29413173\n",
      "Mean:  0.009217994\n",
      "Var:  0.026132792\n",
      "Bias:  -0.028675368\n",
      "Input:  0.11881254\n",
      "Mean:  0.017785337\n",
      "Var:  0.030030472\n",
      "Bias:  0.21085775\n",
      "Input:  0.49542314\n",
      "Mean:  -0.0050863177\n",
      "Var:  0.029205512\n",
      "Bias:  -0.027436297\n",
      "Input:  -0.10881738\n",
      "Mean:  0.022773154\n",
      "Var:  0.032643758\n",
      "Bias:  -0.068205506\n",
      "Input:  0.29616496\n",
      "Mean:  0.011199062\n",
      "Var:  0.024292422\n",
      "Bias:  -0.13995466\n",
      "Input:  0.03923033\n",
      "Mean:  0.023742916\n",
      "Var:  0.037096262\n",
      "Bias:  -0.00011514779\n",
      "Input:  0.3797715\n",
      "Mean:  0.017959833\n",
      "Var:  0.049247794\n",
      "Bias:  -0.10420394\n",
      "Input:  0.18315339\n",
      "Mean:  -0.017684184\n",
      "Var:  0.018146094\n",
      "Bias:  -0.09550629\n",
      "Input:  -0.37845322\n",
      "Mean:  0.013375184\n",
      "Var:  0.044600368\n",
      "Bias:  0.30962667\n",
      "Input:  0.5236296\n",
      "Mean:  -0.010681614\n",
      "Var:  0.06185463\n",
      "Bias:  0.10688135\n",
      "Input:  -0.06402448\n",
      "Mean:  0.0032855254\n",
      "Var:  0.049163893\n",
      "Bias:  -0.22032858\n",
      "Input:  -0.16776018\n",
      "Mean:  0.003053816\n",
      "Var:  0.03211623\n",
      "Bias:  -0.16904064\n",
      "Input:  -0.12017958\n",
      "Mean:  0.007714372\n",
      "Var:  0.02994527\n",
      "Bias:  -0.10024783\n",
      "Input:  0.023182124\n",
      "Mean:  0.025705911\n",
      "Var:  0.024001205\n",
      "Bias:  0.028058624\n",
      "Input:  0.4393532\n",
      "Mean:  -0.014016521\n",
      "Var:  0.025101406\n",
      "Bias:  0.17913118\n",
      "Input:  -0.04513316\n",
      "Mean:  -0.020488808\n",
      "Var:  0.00909781\n",
      "Bias:  -0.0010389212\n",
      "Input:  -0.32885984\n",
      "Mean:  0.0048923\n",
      "Var:  0.023140846\n",
      "Bias:  -0.09880287\n",
      "Input:  -0.020526074\n",
      "Mean:  -0.023405438\n",
      "Var:  0.048858993\n",
      "Bias:  -0.03191339\n",
      "Input:  -0.4064004\n",
      "Mean:  0.015513288\n",
      "Var:  0.027222577\n",
      "Bias:  -0.14490375\n",
      "Input:  0.10330886\n",
      "Mean:  0.012560088\n",
      "Var:  0.02985806\n",
      "Bias:  -0.08872522\n",
      "Input:  0.112236194\n",
      "Mean:  -0.023955384\n",
      "Var:  0.0054634702\n",
      "Bias:  0.0\n",
      "Input:  -0.38328615\n",
      "Mean:  -0.0028159944\n",
      "Var:  0.022284172\n",
      "Bias:  0.12693286\n",
      "Input:  0.08187695\n",
      "Mean:  -0.020217638\n",
      "Var:  0.006028772\n",
      "Bias:  0.0\n",
      "Input:  -0.32348222\n",
      "Mean:  -0.044994228\n",
      "Var:  0.00387345\n",
      "Bias:  0.0\n",
      "Input:  -0.71990764\n",
      "Mean:  0.0077845883\n",
      "Var:  0.027241003\n",
      "Bias:  -0.11735553\n",
      "Input:  0.0071978793\n",
      "Mean:  0.00212856\n",
      "Var:  0.02381124\n",
      "Bias:  0.048969053\n",
      "Input:  0.083026014\n",
      "Mean:  0.022343885\n",
      "Var:  0.010125946\n",
      "Bias:  -0.18150158\n",
      "Input:  0.17600058\n",
      "Mean:  0.031709276\n",
      "Var:  0.027301678\n",
      "Bias:  -0.033604436\n",
      "Input:  0.47374398\n",
      "Mean:  0.016275998\n",
      "Var:  0.044321574\n",
      "Bias:  0.06165055\n",
      "Input:  0.32206652\n",
      "Mean:  -0.0023637954\n",
      "Var:  0.03527452\n",
      "Bias:  0.03066525\n",
      "Input:  -0.007155476\n",
      "Mean:  0.03363495\n",
      "Var:  0.029669637\n",
      "Bias:  0.1378931\n",
      "Input:  0.6760523\n",
      "Mean:  -0.018291458\n",
      "Var:  0.046799324\n",
      "Bias:  0.2583961\n",
      "Input:  -0.034267247\n",
      "Mean:  -0.058350094\n",
      "Var:  0.0049567185\n",
      "Bias:  0.0\n",
      "Input:  -0.9336015\n",
      "Mean:  -0.023692224\n",
      "Var:  0.0051029683\n",
      "Bias:  0.0\n",
      "Input:  -0.3790756\n",
      "Mean:  -0.03211861\n",
      "Var:  0.008023558\n",
      "Bias:  -0.0019561748\n",
      "Input:  -0.51585394\n",
      "Mean:  -0.012250011\n",
      "Var:  0.03196024\n",
      "Bias:  0.00245076\n",
      "Input:  -0.19354941\n",
      "Mean:  -0.047658283\n",
      "Var:  0.008665957\n",
      "Bias:  0.0\n",
      "Input:  -0.76253253\n",
      "Mean:  -0.008852625\n",
      "Var:  0.019207655\n",
      "Bias:  0.09621079\n",
      "Input:  -0.04543121\n",
      "Mean:  0.024814207\n",
      "Var:  0.014672536\n",
      "Bias:  -0.058778875\n",
      "Input:  0.33824843\n",
      "Mean:  0.005819453\n",
      "Var:  0.014867917\n",
      "Bias:  -0.19879836\n",
      "Input:  -0.10568711\n",
      "Mean:  -0.028498739\n",
      "Var:  0.006699598\n",
      "Bias:  0.0\n",
      "Input:  -0.45597982\n",
      "Mean:  0.02350464\n",
      "Var:  0.029486919\n",
      "Bias:  0.17216587\n",
      "Input:  0.5482401\n",
      "Mean:  -0.020773645\n",
      "Var:  0.009827287\n",
      "Bias:  -0.025242321\n",
      "Input:  -0.35762066\n",
      "Mean:  0.010123288\n",
      "Var:  0.029473871\n",
      "Bias:  0.050328862\n",
      "Input:  0.21230148\n",
      "Mean:  0.010446813\n",
      "Var:  0.03244778\n",
      "Bias:  -0.21192463\n",
      "Input:  -0.04477562\n",
      "Mean:  0.022327997\n",
      "Var:  0.0529554\n",
      "Bias:  0.32297924\n",
      "Input:  0.68022716\n",
      "Mean:  -0.004473065\n",
      "Var:  0.033233125\n",
      "Bias:  0.18966186\n",
      "Input:  0.11809282\n",
      "Mean:  -0.036278635\n",
      "Var:  0.007809993\n",
      "Bias:  0.0\n",
      "Input:  -0.58045816\n",
      "Mean:  0.011998186\n",
      "Var:  0.03278164\n",
      "Bias:  0.16086957\n",
      "Input:  0.35284054\n",
      "Mean:  0.016429612\n",
      "Var:  0.035754506\n",
      "Bias:  0.22354344\n",
      "Input:  0.48641723\n",
      "Mean:  0.008267244\n",
      "Var:  0.04225069\n",
      "Bias:  -0.2680902\n",
      "Input:  -0.13581428\n",
      "Mean:  0.011056513\n",
      "Var:  0.038930804\n",
      "Bias:  0.034722928\n",
      "Input:  0.21162713\n",
      "Mean:  -0.0032422915\n",
      "Var:  0.028212935\n",
      "Bias:  0.3018087\n",
      "Input:  0.24993205\n",
      "Mean:  0.010114014\n",
      "Var:  0.017243588\n",
      "Bias:  -0.13724688\n",
      "Input:  0.02457735\n",
      "Mean:  -0.0143771665\n",
      "Var:  0.0038926154\n",
      "Bias:  -0.023305902\n",
      "Input:  -0.25334057\n",
      "Mean:  0.015345883\n",
      "Var:  0.019335844\n",
      "Bias:  -0.11924044\n",
      "Input:  0.12629369\n",
      "Mean:  -0.0143530015\n",
      "Var:  0.010040738\n",
      "Bias:  0.0\n",
      "Input:  -0.22964802\n",
      "Mean:  0.026158353\n",
      "Var:  0.0411022\n",
      "Bias:  -0.39141887\n",
      "Input:  0.027114779\n",
      "Mean:  -0.012922071\n",
      "Var:  0.0066489168\n",
      "Bias:  0.0\n",
      "Input:  -0.20675313\n",
      "Mean:  0.0030484386\n",
      "Var:  0.028626304\n",
      "Bias:  -0.14926969\n",
      "Input:  -0.10049467\n",
      "Mean:  0.041866377\n",
      "Var:  0.047509026\n",
      "Bias:  0.12802157\n",
      "Input:  0.7978836\n",
      "Mean:  -0.0018902281\n",
      "Var:  0.028679645\n",
      "Bias:  0.056486044\n",
      "Input:  0.026242394\n",
      "Mean:  -0.015713926\n",
      "Var:  0.023591418\n",
      "Bias:  0.031238412\n",
      "Input:  -0.22018442\n",
      "Mean:  0.02433943\n",
      "Var:  0.02480064\n",
      "Bias:  -0.004877738\n",
      "Input:  0.38455313\n",
      "Mean:  -0.018535016\n",
      "Var:  0.0046398807\n",
      "Bias:  -0.004207181\n",
      "Input:  -0.30076745\n",
      "Mean:  0.012600201\n",
      "Var:  0.048503608\n",
      "Bias:  0.35802794\n",
      "Input:  0.55963117\n",
      "Mean:  0.03109063\n",
      "Var:  0.028275982\n",
      "Bias:  0.16394013\n",
      "Input:  0.6613902\n",
      "Mean:  -0.020289928\n",
      "Var:  0.005259482\n",
      "Bias:  0.0\n",
      "Input:  -0.32463884\n",
      "Mean:  -0.020254672\n",
      "Var:  0.009098567\n",
      "Bias:  0.0\n",
      "Input:  -0.32407475\n",
      "Mean:  0.021920957\n",
      "Var:  0.021751389\n",
      "Bias:  0.012252987\n",
      "Input:  0.3629883\n",
      "Mean:  -0.005927786\n",
      "Var:  0.04391606\n",
      "Bias:  -0.17640145\n",
      "Input:  -0.27124602\n",
      "Mean:  -0.008491937\n",
      "Var:  0.033437714\n",
      "Bias:  0.116479546\n",
      "Input:  -0.019391447\n",
      "Mean:  -0.040763106\n",
      "Var:  0.0069726896\n",
      "Bias:  0.0\n",
      "Input:  -0.6522097\n",
      "Mean:  -0.020944148\n",
      "Var:  0.03058224\n",
      "Bias:  -0.010676136\n",
      "Input:  -0.34578252\n",
      "Mean:  0.026200743\n",
      "Var:  0.036815017\n",
      "Bias:  -0.113313876\n",
      "Input:  0.305898\n",
      "Mean:  -0.0047682617\n",
      "Var:  0.027116137\n",
      "Bias:  -0.088636875\n",
      "Input:  -0.16492906\n",
      "Mean:  -0.020406168\n",
      "Var:  0.0074419943\n",
      "Bias:  0.0\n",
      "Input:  -0.3264987\n",
      "Mean:  0.007468827\n",
      "Var:  0.027344923\n",
      "Bias:  -0.06441719\n",
      "Input:  0.055084042\n",
      "Mean:  0.0022038613\n",
      "Var:  0.031558692\n",
      "Bias:  0.21582663\n",
      "Input:  0.2510884\n",
      "Mean:  -0.02824138\n",
      "Var:  0.005370674\n",
      "Bias:  0.009108469\n",
      "Input:  -0.4427536\n",
      "Mean:  0.028826267\n",
      "Var:  0.025727997\n",
      "Bias:  -0.14362504\n",
      "Input:  0.31759524\n",
      "Mean:  0.0074752234\n",
      "Var:  0.038717154\n",
      "Bias:  0.44430685\n",
      "Input:  0.5639104\n",
      "Mean:  0.0106261885\n",
      "Var:  0.017086016\n",
      "Bias:  -0.18728931\n",
      "Input:  -0.017270297\n",
      "Mean:  -0.016590923\n",
      "Var:  0.0074646985\n",
      "Bias:  -0.0032565412\n",
      "Input:  -0.2687113\n",
      "Mean:  -0.006840687\n",
      "Var:  0.028171945\n",
      "Bias:  0.06946228\n",
      "Input:  -0.03998871\n",
      "Mean:  -0.0017432868\n",
      "Var:  0.018928606\n",
      "Bias:  -0.103532776\n",
      "Input:  -0.13142537\n",
      "Mean:  -0.0020244196\n",
      "Var:  0.018116415\n",
      "Bias:  -0.12597078\n",
      "Input:  -0.1583615\n",
      "Mean:  -0.0071171615\n",
      "Var:  0.033717994\n",
      "Bias:  -0.13101421\n",
      "Input:  -0.2448888\n",
      "Mean:  0.031336114\n",
      "Var:  0.037391357\n",
      "Bias:  -0.06815172\n",
      "Input:  0.4332261\n",
      "Mean:  -0.0014526593\n",
      "Var:  0.024839543\n",
      "Bias:  0.17501402\n",
      "Input:  0.15177147\n",
      "Mean:  0.016926177\n",
      "Var:  0.041119296\n",
      "Bias:  0.05350046\n",
      "Input:  0.3243193\n",
      "Mean:  0.0095020905\n",
      "Var:  0.04886104\n",
      "Bias:  0.1416122\n",
      "Input:  0.29364565\n",
      "Mean:  0.009699028\n",
      "Var:  0.039800618\n",
      "Bias:  0.09963778\n",
      "Input:  0.25482222\n",
      "Mean:  -0.0076482184\n",
      "Var:  0.013449226\n",
      "Bias:  0.07951745\n",
      "Input:  -0.04285405\n",
      "Mean:  0.0073259715\n",
      "Var:  0.024383403\n",
      "Bias:  0.15351279\n",
      "Input:  0.27072835\n",
      "Mean:  0.04102689\n",
      "Var:  0.045188088\n",
      "Bias:  -0.0011266717\n",
      "Input:  0.6553036\n",
      "Mean:  -0.013184728\n",
      "Var:  0.008111667\n",
      "Bias:  0.0\n",
      "Input:  -0.21095565\n",
      "Mean:  -0.051451664\n",
      "Var:  0.008324029\n",
      "Bias:  0.0\n",
      "Input:  -0.82322663\n",
      "Mean:  0.00831686\n",
      "Var:  0.02213212\n",
      "Bias:  0.041885715\n",
      "Input:  0.17495547\n",
      "Mean:  -0.029024234\n",
      "Var:  0.0073670135\n",
      "Bias:  -0.00212459\n",
      "Input:  -0.46651232\n",
      "Mean:  0.0014591115\n",
      "Var:  0.019994285\n",
      "Bias:  0.11185914\n",
      "Input:  0.13520493\n",
      "Mean:  0.017710166\n",
      "Var:  0.014014121\n",
      "Bias:  0.009426513\n",
      "Input:  0.29278916\n",
      "Mean:  0.0075257337\n",
      "Var:  0.022155665\n",
      "Bias:  0.061803203\n",
      "Input:  0.18221495\n",
      "DeepExplain: running \"shapley\" explanation method (6)\n",
      "Model with multiple inputs:  False\n",
      "Shapley: computing references...\n",
      "model_2/dense_2/MatMul_x (1, 128)\n",
      "model_2/dense_1/MatMul_w (16, 128)\n",
      "model_3/dense_1/MatMul_b (128,)\n",
      "model_2/dense_3/MatMul_x (1, 128)\n",
      "model_2/dense_2/MatMul_b (128,)\n",
      "model_2/dense_3/MatMul_b (10,)\n",
      "model_2/dense_1/MatMul_b (128,)\n",
      "model_3/dense_3/MatMul_b (10,)\n",
      "model_2/dense_1/MatMul_x (1, 16)\n",
      "model_3/dense_1/MatMul_w (16, 128)\n",
      "model_3/dense_2/MatMul_w (128, 128)\n",
      "model_3/dense_2/MatMul_b (128,)\n",
      "model_3/dense_3/MatMul_w (128, 10)\n",
      "model_3/dense_2/MatMul_x (1, 128)\n",
      "model_3/dense_1/MatMul_x (1, 16)\n",
      "model_2/dense_2/MatMul_w (128, 128)\n",
      "model_3/dense_3/MatMul_x (1, 128)\n",
      "model_2/dense_3/MatMul_w (128, 10)\n",
      "Shapley: references ready\n",
      "(1, 128)\n",
      "(128, 10)\n",
      "(10,)\n",
      "(1, 128)\n",
      "Skip dense_3\n",
      "(1, 128)\n",
      "(128, 128)\n",
      "(128,)\n",
      "(1, 128)\n",
      "Mean:  0.011347102\n",
      "Var:  0.002044505\n",
      "Bias:  -0.057858586\n",
      "Input:  1.3945705\n",
      "Mean:  -0.0027440835\n",
      "Var:  0.00038091207\n",
      "Bias:  0.0\n",
      "Input:  -0.3512427\n",
      "Mean:  0.006783667\n",
      "Var:  0.0013703178\n",
      "Bias:  -0.08044167\n",
      "Input:  0.7878677\n",
      "Mean:  -0.0076357424\n",
      "Var:  0.0027246526\n",
      "Bias:  0.011946435\n",
      "Input:  -0.9654286\n",
      "Mean:  -0.0018049118\n",
      "Var:  0.0021731497\n",
      "Bias:  -0.008518126\n",
      "Input:  -0.23954684\n",
      "Mean:  0.02878411\n",
      "Var:  0.0069349175\n",
      "Bias:  0.14418365\n",
      "Input:  3.8285496\n",
      "Mean:  -0.018207602\n",
      "Var:  0.005070991\n",
      "Bias:  -0.06340704\n",
      "Input:  -2.39398\n",
      "Mean:  -0.007802947\n",
      "Var:  0.0033997286\n",
      "Bias:  -0.014046046\n",
      "Input:  -1.0128232\n",
      "Mean:  0.007560541\n",
      "Var:  0.0012698038\n",
      "Bias:  -0.06695735\n",
      "Input:  0.9007919\n",
      "Mean:  0.014900644\n",
      "Var:  0.0048623052\n",
      "Bias:  0.1827435\n",
      "Input:  2.090026\n",
      "Mean:  -0.0005403267\n",
      "Var:  0.00056812435\n",
      "Bias:  0.010533356\n",
      "Input:  -0.058628462\n",
      "Mean:  -0.0020468705\n",
      "Var:  0.0025475707\n",
      "Bias:  0.11046493\n",
      "Input:  -0.1515345\n",
      "Mean:  0.020095265\n",
      "Var:  0.004969259\n",
      "Bias:  0.2826237\n",
      "Input:  2.8548176\n",
      "Mean:  0.012464081\n",
      "Var:  0.003786855\n",
      "Bias:  -0.08484463\n",
      "Input:  1.5105578\n",
      "Mean:  0.0045605246\n",
      "Var:  0.001187348\n",
      "Bias:  0.07330768\n",
      "Input:  0.65705484\n",
      "Mean:  0.0025872742\n",
      "Var:  0.00357093\n",
      "Bias:  -0.04518252\n",
      "Input:  0.28598857\n",
      "Mean:  -0.018242517\n",
      "Var:  0.0058438852\n",
      "Bias:  -0.060115118\n",
      "Input:  -2.3951573\n",
      "Mean:  -0.008462431\n",
      "Var:  0.004352161\n",
      "Bias:  -0.07350688\n",
      "Input:  -1.156698\n",
      "Mean:  0.008055729\n",
      "Var:  0.0027454915\n",
      "Bias:  0.110496394\n",
      "Input:  1.1416297\n",
      "Mean:  0.0013079657\n",
      "Var:  0.0032352745\n",
      "Bias:  -0.063870005\n",
      "Input:  0.10354961\n",
      "Mean:  -0.012958445\n",
      "Var:  0.0031699936\n",
      "Bias:  -0.010323454\n",
      "Input:  -1.6690043\n",
      "Mean:  0.009416604\n",
      "Var:  0.002329126\n",
      "Bias:  0.073357\n",
      "Input:  1.2786824\n",
      "Mean:  -0.014199053\n",
      "Var:  0.0052994457\n",
      "Bias:  0.20601793\n",
      "Input:  -1.6114608\n",
      "Mean:  0.01437614\n",
      "Var:  0.003313893\n",
      "Bias:  0.053296167\n",
      "Input:  1.8934422\n",
      "Mean:  -0.0006571433\n",
      "Var:  0.0033544316\n",
      "Bias:  -0.083972074\n",
      "Input:  -0.16808641\n",
      "Mean:  -0.0044870754\n",
      "Var:  0.002427755\n",
      "Bias:  0.078208014\n",
      "Input:  -0.49613762\n",
      "Mean:  0.0032277284\n",
      "Var:  0.0025634882\n",
      "Bias:  -0.0531924\n",
      "Input:  0.35995683\n",
      "Mean:  0.0035879165\n",
      "Var:  0.003916147\n",
      "Bias:  -0.0060260515\n",
      "Input:  0.45322725\n",
      "Mean:  -0.0017768149\n",
      "Var:  0.000357024\n",
      "Bias:  -0.04493023\n",
      "Input:  -0.27236253\n",
      "Mean:  -0.0042250045\n",
      "Var:  0.0027701582\n",
      "Bias:  0.11841779\n",
      "Input:  -0.42238277\n",
      "Mean:  0.0037292007\n",
      "Var:  0.0033984627\n",
      "Bias:  0.097436085\n",
      "Input:  0.5747738\n",
      "Mean:  -0.0016577889\n",
      "Var:  0.0020718565\n",
      "Bias:  -0.074442305\n",
      "Input:  -0.28663927\n",
      "Mean:  0.005355318\n",
      "Var:  0.002014954\n",
      "Bias:  0.21326208\n",
      "Input:  0.8987428\n",
      "Mean:  0.011412114\n",
      "Var:  0.005960134\n",
      "Bias:  -0.010247336\n",
      "Input:  1.4505032\n",
      "Mean:  -0.022162456\n",
      "Var:  0.0062940903\n",
      "Bias:  -0.027724274\n",
      "Input:  -2.8645186\n",
      "Mean:  0.004601187\n",
      "Var:  0.001979902\n",
      "Bias:  -0.074137434\n",
      "Input:  0.5148145\n",
      "Mean:  -0.0014360728\n",
      "Var:  0.0016733891\n",
      "Bias:  -0.06604534\n",
      "Input:  -0.24986264\n",
      "Mean:  -0.023141244\n",
      "Var:  0.007002432\n",
      "Bias:  0.061433025\n",
      "Input:  -2.9006462\n",
      "Mean:  0.0011208667\n",
      "Var:  0.0025114259\n",
      "Bias:  0.12644745\n",
      "Input:  0.26991838\n",
      "Mean:  -0.011140796\n",
      "Var:  0.0036167041\n",
      "Bias:  -0.056290247\n",
      "Input:  -1.4823122\n",
      "Mean:  -0.004284686\n",
      "Var:  0.00059515645\n",
      "Bias:  -0.08166838\n",
      "Input:  -0.6301082\n",
      "Mean:  0.014752476\n",
      "Var:  0.0048077162\n",
      "Bias:  0.16548854\n",
      "Input:  2.0538054\n",
      "Mean:  -0.013579102\n",
      "Var:  0.0038030348\n",
      "Bias:  -0.054292087\n",
      "Input:  -1.7924172\n",
      "Mean:  0.004033018\n",
      "Var:  0.0028418466\n",
      "Bias:  0.040864024\n",
      "Input:  0.55709034\n",
      "Mean:  0.005172055\n",
      "Var:  0.0015163156\n",
      "Bias:  0.16210227\n",
      "Input:  0.82412535\n",
      "Mean:  0.0031937757\n",
      "Var:  0.001331347\n",
      "Bias:  0.04204441\n",
      "Input:  0.4508477\n",
      "Mean:  0.016185801\n",
      "Var:  0.004558871\n",
      "Bias:  0.1810344\n",
      "Input:  2.252817\n",
      "Mean:  -0.0013888697\n",
      "Var:  0.00052037096\n",
      "Bias:  -0.02109085\n",
      "Input:  -0.19886617\n",
      "Mean:  0.018134087\n",
      "Var:  0.004357828\n",
      "Bias:  0.076880425\n",
      "Input:  2.3980436\n",
      "Mean:  -0.009934277\n",
      "Var:  0.0013631836\n",
      "Bias:  0.0046670935\n",
      "Input:  -1.2669204\n",
      "Mean:  0.00071967323\n",
      "Var:  0.0030298715\n",
      "Bias:  0.013865315\n",
      "Input:  0.10598349\n",
      "Mean:  0.009946028\n",
      "Var:  0.0043306295\n",
      "Bias:  0.062102832\n",
      "Input:  1.3351943\n",
      "Mean:  -0.01128045\n",
      "Var:  0.0031987745\n",
      "Bias:  0.13057958\n",
      "Input:  -1.313318\n",
      "Mean:  0.0080694165\n",
      "Var:  0.00306089\n",
      "Bias:  -0.06205091\n",
      "Input:  0.9708344\n",
      "Mean:  -0.0077284807\n",
      "Var:  0.002762992\n",
      "Bias:  -0.12844206\n",
      "Input:  -1.1176876\n",
      "Mean:  0.0135363545\n",
      "Var:  0.002425472\n",
      "Bias:  -0.051283363\n",
      "Input:  1.68137\n",
      "Mean:  -0.0020921724\n",
      "Var:  0.00038952322\n",
      "Bias:  0.010033392\n",
      "Input:  -0.25776467\n",
      "Mean:  0.009838015\n",
      "Var:  0.00419147\n",
      "Bias:  0.10333439\n",
      "Input:  1.3626003\n",
      "Mean:  0.0059659006\n",
      "Var:  0.0014737882\n",
      "Bias:  0.07112985\n",
      "Input:  0.83476514\n",
      "Mean:  -0.009587465\n",
      "Var:  0.0048127715\n",
      "Bias:  0.035214722\n",
      "Input:  -1.1919808\n",
      "Mean:  -0.02036456\n",
      "Var:  0.006132948\n",
      "Bias:  -0.0378927\n",
      "Input:  -2.6445565\n",
      "Mean:  -0.00084108824\n",
      "Var:  0.0013093741\n",
      "Bias:  0.099981636\n",
      "Input:  -0.0076776594\n",
      "Mean:  -0.001123351\n",
      "Var:  0.0015181669\n",
      "Bias:  0.10922885\n",
      "Input:  -0.034560084\n",
      "Mean:  -0.0016171458\n",
      "Var:  0.00045021868\n",
      "Bias:  -0.01615183\n",
      "Input:  -0.2231465\n",
      "Mean:  0.012950383\n",
      "Var:  0.0026133358\n",
      "Bias:  0.10186917\n",
      "Input:  1.7595183\n",
      "Mean:  0.013839252\n",
      "Var:  0.0029581978\n",
      "Bias:  -0.094438694\n",
      "Input:  1.6769856\n",
      "Mean:  0.013980458\n",
      "Var:  0.001753648\n",
      "Bias:  -0.061448555\n",
      "Input:  1.72805\n",
      "Mean:  0.008770386\n",
      "Var:  0.0021292458\n",
      "Bias:  0.11301957\n",
      "Input:  1.235629\n",
      "Mean:  -0.0037207077\n",
      "Var:  0.0005308484\n",
      "Bias:  -0.014963649\n",
      "Input:  -0.49121425\n",
      "Mean:  0.01877912\n",
      "Var:  0.0054484634\n",
      "Bias:  0.020704098\n",
      "Input:  2.4244313\n",
      "Mean:  -0.004971165\n",
      "Var:  0.004060363\n",
      "Bias:  0.1338124\n",
      "Input:  -0.5024967\n",
      "Mean:  0.014396446\n",
      "Var:  0.0022530355\n",
      "Bias:  -0.042609636\n",
      "Input:  1.8001354\n",
      "Mean:  0.017807689\n",
      "Var:  0.0033508644\n",
      "Bias:  0.0026638713\n",
      "Input:  2.282048\n",
      "Mean:  0.014265787\n",
      "Var:  0.004212893\n",
      "Bias:  0.28011876\n",
      "Input:  2.1061394\n",
      "Mean:  -0.010280991\n",
      "Var:  0.0031043794\n",
      "Bias:  -0.058580097\n",
      "Input:  -1.3745469\n",
      "Mean:  0.0018805009\n",
      "Var:  0.0022648503\n",
      "Bias:  -0.044033382\n",
      "Input:  0.19667074\n",
      "Mean:  -0.00060295034\n",
      "Var:  0.00051680463\n",
      "Bias:  -0.010452749\n",
      "Input:  -0.08763039\n",
      "Mean:  -0.006375627\n",
      "Var:  0.0019991333\n",
      "Bias:  -0.0293275\n",
      "Input:  -0.8454078\n",
      "Mean:  -0.006518529\n",
      "Var:  0.002784454\n",
      "Bias:  -0.1167312\n",
      "Input:  -0.95110285\n",
      "Mean:  0.0051587913\n",
      "Var:  0.0033924123\n",
      "Bias:  0.13684025\n",
      "Input:  0.7971655\n",
      "Mean:  -0.0037034252\n",
      "Var:  0.00082754425\n",
      "Bias:  0.005985653\n",
      "Input:  -0.46805277\n",
      "Mean:  -0.005056395\n",
      "Var:  0.0034303605\n",
      "Bias:  0.11067539\n",
      "Input:  -0.5365432\n",
      "Mean:  0.008988566\n",
      "Var:  0.0035095725\n",
      "Bias:  0.18436782\n",
      "Input:  1.3349042\n",
      "Mean:  0.010761239\n",
      "Var:  0.0018790285\n",
      "Bias:  -0.06153365\n",
      "Input:  1.3159049\n",
      "Mean:  0.008843625\n",
      "Var:  0.0041596997\n",
      "Bias:  -0.046093415\n",
      "Input:  1.0858905\n",
      "Mean:  -0.0019998564\n",
      "Var:  0.00045580723\n",
      "Bias:  -0.042268824\n",
      "Input:  -0.29825044\n",
      "Mean:  0.0066497256\n",
      "Var:  0.0012373992\n",
      "Bias:  0.17100836\n",
      "Input:  1.0221733\n",
      "Mean:  -0.0014840385\n",
      "Var:  0.0005119505\n",
      "Bias:  -0.008459542\n",
      "Input:  -0.19841647\n",
      "Mean:  -0.010834285\n",
      "Var:  0.0020819844\n",
      "Bias:  0.12188793\n",
      "Input:  -1.2649006\n",
      "Mean:  0.0036681257\n",
      "Var:  0.0018692568\n",
      "Bias:  0.040011823\n",
      "Input:  0.5095319\n",
      "Mean:  -0.004375826\n",
      "Var:  0.0005033009\n",
      "Bias:  -0.022652758\n",
      "Input:  -0.5827585\n",
      "Mean:  -0.003207646\n",
      "Var:  0.0040509757\n",
      "Bias:  -0.07870487\n",
      "Input:  -0.48928356\n",
      "Mean:  -0.0023280298\n",
      "Var:  0.00043828358\n",
      "Bias:  -0.023336343\n",
      "Input:  -0.32132417\n",
      "Mean:  -0.006392937\n",
      "Var:  0.0047772992\n",
      "Bias:  -0.06126035\n",
      "Input:  -0.8795563\n",
      "Mean:  -0.009224819\n",
      "Var:  0.0033913078\n",
      "Bias:  0.04733586\n",
      "Input:  -1.133441\n",
      "Mean:  -0.004471449\n",
      "Var:  0.00039253212\n",
      "Bias:  -5.4145396e-05\n",
      "Input:  -0.5723996\n",
      "Mean:  0.00021130824\n",
      "Var:  0.004482312\n",
      "Bias:  0.07998488\n",
      "Input:  0.10703234\n",
      "Mean:  -0.0023136514\n",
      "Var:  0.0032157702\n",
      "Bias:  0.07106902\n",
      "Input:  -0.22507836\n",
      "Mean:  0.0075466754\n",
      "Var:  0.0017920546\n",
      "Bias:  0.06043553\n",
      "Input:  1.02641\n",
      "Mean:  0.012942668\n",
      "Var:  0.0026485762\n",
      "Bias:  0.074772075\n",
      "Input:  1.7314336\n",
      "Mean:  -0.0072433874\n",
      "Var:  0.0048182\n",
      "Bias:  0.15913257\n",
      "Input:  -0.768021\n",
      "Mean:  0.0055991146\n",
      "Var:  0.0029588402\n",
      "Bias:  0.0143001145\n",
      "Input:  0.7309868\n",
      "Mean:  0.004727384\n",
      "Var:  0.0014897508\n",
      "Bias:  0.01024559\n",
      "Input:  0.6153507\n",
      "Mean:  -0.010084579\n",
      "Var:  0.0044356077\n",
      "Bias:  0.06481828\n",
      "Input:  -1.2260078\n",
      "Mean:  0.007265438\n",
      "Var:  0.0026497669\n",
      "Bias:  -0.11149632\n",
      "Input:  0.8184797\n",
      "Mean:  0.008260281\n",
      "Var:  0.0024395096\n",
      "Bias:  -0.045107655\n",
      "Input:  1.0122083\n",
      "Mean:  -0.015969202\n",
      "Var:  0.004245421\n",
      "Bias:  0.04760345\n",
      "Input:  -1.9964544\n",
      "Mean:  -0.0013634536\n",
      "Var:  0.0004054772\n",
      "Bias:  -0.04133164\n",
      "Input:  -0.21585369\n",
      "Mean:  -0.005568689\n",
      "Var:  0.003102501\n",
      "Bias:  0.06800593\n",
      "Input:  -0.6447863\n",
      "Mean:  0.0019831553\n",
      "Var:  0.002486635\n",
      "Bias:  -0.18760405\n",
      "Input:  0.06623982\n",
      "Mean:  -0.0052884454\n",
      "Var:  0.0028881761\n",
      "Bias:  -0.13458739\n",
      "Input:  -0.8115084\n",
      "Mean:  -0.011340996\n",
      "Var:  0.0045238873\n",
      "Bias:  0.16149023\n",
      "Input:  -1.2901573\n",
      "Mean:  -0.0037796125\n",
      "Var:  0.0022559864\n",
      "Bias:  0.062965706\n",
      "Input:  -0.4208247\n",
      "Mean:  -0.008522403\n",
      "Var:  0.0019667961\n",
      "Bias:  0.023896977\n",
      "Input:  -1.0669707\n",
      "Mean:  -0.014894748\n",
      "Var:  0.0056423056\n",
      "Bias:  0.09446706\n",
      "Input:  -1.8120607\n",
      "Mean:  0.0073873284\n",
      "Var:  0.0021463057\n",
      "Bias:  -0.013912526\n",
      "Input:  0.93166554\n",
      "Mean:  -0.003345368\n",
      "Var:  0.00055792625\n",
      "Bias:  0.0\n",
      "Input:  -0.4282071\n",
      "Mean:  -0.0019394034\n",
      "Var:  0.0007200696\n",
      "Bias:  -0.014310414\n",
      "Input:  -0.26255405\n",
      "Mean:  0.00036848523\n",
      "Var:  0.0005399763\n",
      "Bias:  0.009461048\n",
      "Input:  0.056627158\n",
      "Mean:  -0.008754725\n",
      "Var:  0.002680283\n",
      "Bias:  0.026054017\n",
      "Input:  -1.0945507\n",
      "Mean:  0.001360758\n",
      "Var:  0.0019361224\n",
      "Bias:  0.17024347\n",
      "Input:  0.3444205\n",
      "Mean:  0.0069666263\n",
      "Var:  0.0026322652\n",
      "Bias:  0.06561508\n",
      "Input:  0.9573432\n",
      "Mean:  -0.003078593\n",
      "Var:  0.00047612947\n",
      "Bias:  -0.012527016\n",
      "Input:  -0.40658692\n",
      "Mean:  0.030859694\n",
      "Var:  0.0066914554\n",
      "Bias:  0.03295737\n",
      "Input:  3.9829981\n",
      "Mean:  0.00639741\n",
      "Var:  0.003548684\n",
      "Bias:  0.052794017\n",
      "Input:  0.8716625\n",
      "Mean:  0.009755712\n",
      "Var:  0.0017100084\n",
      "Bias:  -0.06931771\n",
      "Input:  1.1794134\n",
      "Mean:  -0.013566315\n",
      "Var:  0.0069552083\n",
      "Bias:  0.049638025\n",
      "Input:  -1.6868503\n",
      "Mean:  0.0037294708\n",
      "Var:  0.0022464965\n",
      "Bias:  -0.0385133\n",
      "Input:  0.43885896\n",
      "(1, 16)\n",
      "(16, 128)\n",
      "(128,)\n",
      "(1, 16)\n",
      "Mean:  -0.0004906766\n",
      "Var:  0.026113674\n",
      "Bias:  -0.076982155\n",
      "Input:  -0.08483298\n",
      "Mean:  -0.043630138\n",
      "Var:  0.007243596\n",
      "Bias:  0.0\n",
      "Input:  -0.6980822\n",
      "Mean:  -0.01027857\n",
      "Var:  0.0132513\n",
      "Bias:  -0.05754864\n",
      "Input:  -0.22200575\n",
      "Mean:  -0.0031130323\n",
      "Var:  0.024773164\n",
      "Bias:  0.043527618\n",
      "Input:  -0.006280899\n",
      "Mean:  0.0031508617\n",
      "Var:  0.03286521\n",
      "Bias:  -0.18868592\n",
      "Input:  -0.13827214\n",
      "Mean:  -0.021275777\n",
      "Var:  0.013051255\n",
      "Bias:  0.038241737\n",
      "Input:  -0.3021707\n",
      "Mean:  0.01234559\n",
      "Var:  0.030587584\n",
      "Bias:  -0.010585431\n",
      "Input:  0.18694401\n",
      "Mean:  -0.014496789\n",
      "Var:  0.0066470504\n",
      "Bias:  -0.00014574901\n",
      "Input:  -0.23209438\n",
      "Mean:  -0.0013445355\n",
      "Var:  0.03195165\n",
      "Bias:  0.20120196\n",
      "Input:  0.17968939\n",
      "Mean:  0.018204957\n",
      "Var:  0.0377394\n",
      "Bias:  -0.120139174\n",
      "Input:  0.17114013\n",
      "Mean:  -0.008510575\n",
      "Var:  0.02949888\n",
      "Bias:  0.010542459\n",
      "Input:  -0.12562674\n",
      "Mean:  -0.02458503\n",
      "Var:  0.008482041\n",
      "Bias:  -0.0139995655\n",
      "Input:  -0.40736002\n",
      "Mean:  0.004353122\n",
      "Var:  0.033123724\n",
      "Bias:  -0.15204836\n",
      "Input:  -0.082398415\n",
      "Mean:  -0.0070926584\n",
      "Var:  0.016729632\n",
      "Bias:  0.05926239\n",
      "Input:  -0.054220144\n",
      "Mean:  0.027616724\n",
      "Var:  0.037887182\n",
      "Bias:  0.023430444\n",
      "Input:  0.46529803\n",
      "Mean:  0.012293656\n",
      "Var:  0.019318536\n",
      "Bias:  -0.038677014\n",
      "Input:  0.15802148\n",
      "Mean:  0.025499046\n",
      "Var:  0.021428887\n",
      "Bias:  -0.020544445\n",
      "Input:  0.3874403\n",
      "Mean:  0.014407516\n",
      "Var:  0.017212639\n",
      "Bias:  -0.05690784\n",
      "Input:  0.17361242\n",
      "Mean:  -0.017941533\n",
      "Var:  0.01818349\n",
      "Bias:  -0.062791444\n",
      "Input:  -0.34985596\n",
      "Mean:  0.00842326\n",
      "Var:  0.028894626\n",
      "Bias:  0.13964148\n",
      "Input:  0.27441365\n",
      "Mean:  0.006032627\n",
      "Var:  0.018160636\n",
      "Bias:  -0.024069691\n",
      "Input:  0.072452344\n",
      "Mean:  0.00827181\n",
      "Var:  0.022823744\n",
      "Bias:  0.006423234\n",
      "Input:  0.13877219\n",
      "Mean:  0.023923818\n",
      "Var:  0.020207487\n",
      "Bias:  -0.22876215\n",
      "Input:  0.15401894\n",
      "Mean:  -0.0065933475\n",
      "Var:  0.036816604\n",
      "Bias:  0.2250592\n",
      "Input:  0.119565636\n",
      "Mean:  0.029974744\n",
      "Var:  0.022458034\n",
      "Bias:  -0.18546417\n",
      "Input:  0.29413173\n",
      "Mean:  0.009217994\n",
      "Var:  0.026132792\n",
      "Bias:  -0.028675368\n",
      "Input:  0.11881254\n",
      "Mean:  0.017785337\n",
      "Var:  0.030030472\n",
      "Bias:  0.21085775\n",
      "Input:  0.49542314\n",
      "Mean:  -0.0050863177\n",
      "Var:  0.029205512\n",
      "Bias:  -0.027436297\n",
      "Input:  -0.10881738\n",
      "Mean:  0.022773154\n",
      "Var:  0.032643758\n",
      "Bias:  -0.068205506\n",
      "Input:  0.29616496\n",
      "Mean:  0.011199062\n",
      "Var:  0.024292422\n",
      "Bias:  -0.13995466\n",
      "Input:  0.03923033\n",
      "Mean:  0.023742916\n",
      "Var:  0.037096262\n",
      "Bias:  -0.00011514779\n",
      "Input:  0.3797715\n",
      "Mean:  0.017959833\n",
      "Var:  0.049247794\n",
      "Bias:  -0.10420394\n",
      "Input:  0.18315339\n",
      "Mean:  -0.017684184\n",
      "Var:  0.018146094\n",
      "Bias:  -0.09550629\n",
      "Input:  -0.37845322\n",
      "Mean:  0.013375184\n",
      "Var:  0.044600368\n",
      "Bias:  0.30962667\n",
      "Input:  0.5236296\n",
      "Mean:  -0.010681614\n",
      "Var:  0.06185463\n",
      "Bias:  0.10688135\n",
      "Input:  -0.06402448\n",
      "Mean:  0.0032855254\n",
      "Var:  0.049163893\n",
      "Bias:  -0.22032858\n",
      "Input:  -0.16776018\n",
      "Mean:  0.003053816\n",
      "Var:  0.03211623\n",
      "Bias:  -0.16904064\n",
      "Input:  -0.12017958\n",
      "Mean:  0.007714372\n",
      "Var:  0.02994527\n",
      "Bias:  -0.10024783\n",
      "Input:  0.023182124\n",
      "Mean:  0.025705911\n",
      "Var:  0.024001205\n",
      "Bias:  0.028058624\n",
      "Input:  0.4393532\n",
      "Mean:  -0.014016521\n",
      "Var:  0.025101406\n",
      "Bias:  0.17913118\n",
      "Input:  -0.04513316\n",
      "Mean:  -0.020488808\n",
      "Var:  0.00909781\n",
      "Bias:  -0.0010389212\n",
      "Input:  -0.32885984\n",
      "Mean:  0.0048923\n",
      "Var:  0.023140846\n",
      "Bias:  -0.09880287\n",
      "Input:  -0.020526074\n",
      "Mean:  -0.023405438\n",
      "Var:  0.048858993\n",
      "Bias:  -0.03191339\n",
      "Input:  -0.4064004\n",
      "Mean:  0.015513288\n",
      "Var:  0.027222577\n",
      "Bias:  -0.14490375\n",
      "Input:  0.10330886\n",
      "Mean:  0.012560088\n",
      "Var:  0.02985806\n",
      "Bias:  -0.08872522\n",
      "Input:  0.112236194\n",
      "Mean:  -0.023955384\n",
      "Var:  0.0054634702\n",
      "Bias:  0.0\n",
      "Input:  -0.38328615\n",
      "Mean:  -0.0028159944\n",
      "Var:  0.022284172\n",
      "Bias:  0.12693286\n",
      "Input:  0.08187695\n",
      "Mean:  -0.020217638\n",
      "Var:  0.006028772\n",
      "Bias:  0.0\n",
      "Input:  -0.32348222\n",
      "Mean:  -0.044994228\n",
      "Var:  0.00387345\n",
      "Bias:  0.0\n",
      "Input:  -0.71990764\n",
      "Mean:  0.0077845883\n",
      "Var:  0.027241003\n",
      "Bias:  -0.11735553\n",
      "Input:  0.0071978793\n",
      "Mean:  0.00212856\n",
      "Var:  0.02381124\n",
      "Bias:  0.048969053\n",
      "Input:  0.083026014\n",
      "Mean:  0.022343885\n",
      "Var:  0.010125946\n",
      "Bias:  -0.18150158\n",
      "Input:  0.17600058\n",
      "Mean:  0.031709276\n",
      "Var:  0.027301678\n",
      "Bias:  -0.033604436\n",
      "Input:  0.47374398\n",
      "Mean:  0.016275998\n",
      "Var:  0.044321574\n",
      "Bias:  0.06165055\n",
      "Input:  0.32206652\n",
      "Mean:  -0.0023637954\n",
      "Var:  0.03527452\n",
      "Bias:  0.03066525\n",
      "Input:  -0.007155476\n",
      "Mean:  0.03363495\n",
      "Var:  0.029669637\n",
      "Bias:  0.1378931\n",
      "Input:  0.6760523\n",
      "Mean:  -0.018291458\n",
      "Var:  0.046799324\n",
      "Bias:  0.2583961\n",
      "Input:  -0.034267247\n",
      "Mean:  -0.058350094\n",
      "Var:  0.0049567185\n",
      "Bias:  0.0\n",
      "Input:  -0.9336015\n",
      "Mean:  -0.023692224\n",
      "Var:  0.0051029683\n",
      "Bias:  0.0\n",
      "Input:  -0.3790756\n",
      "Mean:  -0.03211861\n",
      "Var:  0.008023558\n",
      "Bias:  -0.0019561748\n",
      "Input:  -0.51585394\n",
      "Mean:  -0.012250011\n",
      "Var:  0.03196024\n",
      "Bias:  0.00245076\n",
      "Input:  -0.19354941\n",
      "Mean:  -0.047658283\n",
      "Var:  0.008665957\n",
      "Bias:  0.0\n",
      "Input:  -0.76253253\n",
      "Mean:  -0.008852625\n",
      "Var:  0.019207655\n",
      "Bias:  0.09621079\n",
      "Input:  -0.04543121\n",
      "Mean:  0.024814207\n",
      "Var:  0.014672536\n",
      "Bias:  -0.058778875\n",
      "Input:  0.33824843\n",
      "Mean:  0.005819453\n",
      "Var:  0.014867917\n",
      "Bias:  -0.19879836\n",
      "Input:  -0.10568711\n",
      "Mean:  -0.028498739\n",
      "Var:  0.006699598\n",
      "Bias:  0.0\n",
      "Input:  -0.45597982\n",
      "Mean:  0.02350464\n",
      "Var:  0.029486919\n",
      "Bias:  0.17216587\n",
      "Input:  0.5482401\n",
      "Mean:  -0.020773645\n",
      "Var:  0.009827287\n",
      "Bias:  -0.025242321\n",
      "Input:  -0.35762066\n",
      "Mean:  0.010123288\n",
      "Var:  0.029473871\n",
      "Bias:  0.050328862\n",
      "Input:  0.21230148\n",
      "Mean:  0.010446813\n",
      "Var:  0.03244778\n",
      "Bias:  -0.21192463\n",
      "Input:  -0.04477562\n",
      "Mean:  0.022327997\n",
      "Var:  0.0529554\n",
      "Bias:  0.32297924\n",
      "Input:  0.68022716\n",
      "Mean:  -0.004473065\n",
      "Var:  0.033233125\n",
      "Bias:  0.18966186\n",
      "Input:  0.11809282\n",
      "Mean:  -0.036278635\n",
      "Var:  0.007809993\n",
      "Bias:  0.0\n",
      "Input:  -0.58045816\n",
      "Mean:  0.011998186\n",
      "Var:  0.03278164\n",
      "Bias:  0.16086957\n",
      "Input:  0.35284054\n",
      "Mean:  0.016429612\n",
      "Var:  0.035754506\n",
      "Bias:  0.22354344\n",
      "Input:  0.48641723\n",
      "Mean:  0.008267244\n",
      "Var:  0.04225069\n",
      "Bias:  -0.2680902\n",
      "Input:  -0.13581428\n",
      "Mean:  0.011056513\n",
      "Var:  0.038930804\n",
      "Bias:  0.034722928\n",
      "Input:  0.21162713\n",
      "Mean:  -0.0032422915\n",
      "Var:  0.028212935\n",
      "Bias:  0.3018087\n",
      "Input:  0.24993205\n",
      "Mean:  0.010114014\n",
      "Var:  0.017243588\n",
      "Bias:  -0.13724688\n",
      "Input:  0.02457735\n",
      "Mean:  -0.0143771665\n",
      "Var:  0.0038926154\n",
      "Bias:  -0.023305902\n",
      "Input:  -0.25334057\n",
      "Mean:  0.015345883\n",
      "Var:  0.019335844\n",
      "Bias:  -0.11924044\n",
      "Input:  0.12629369\n",
      "Mean:  -0.0143530015\n",
      "Var:  0.010040738\n",
      "Bias:  0.0\n",
      "Input:  -0.22964802\n",
      "Mean:  0.026158353\n",
      "Var:  0.0411022\n",
      "Bias:  -0.39141887\n",
      "Input:  0.027114779\n",
      "Mean:  -0.012922071\n",
      "Var:  0.0066489168\n",
      "Bias:  0.0\n",
      "Input:  -0.20675313\n",
      "Mean:  0.0030484386\n",
      "Var:  0.028626304\n",
      "Bias:  -0.14926969\n",
      "Input:  -0.10049467\n",
      "Mean:  0.041866377\n",
      "Var:  0.047509026\n",
      "Bias:  0.12802157\n",
      "Input:  0.7978836\n",
      "Mean:  -0.0018902281\n",
      "Var:  0.028679645\n",
      "Bias:  0.056486044\n",
      "Input:  0.026242394\n",
      "Mean:  -0.015713926\n",
      "Var:  0.023591418\n",
      "Bias:  0.031238412\n",
      "Input:  -0.22018442\n",
      "Mean:  0.02433943\n",
      "Var:  0.02480064\n",
      "Bias:  -0.004877738\n",
      "Input:  0.38455313\n",
      "Mean:  -0.018535016\n",
      "Var:  0.0046398807\n",
      "Bias:  -0.004207181\n",
      "Input:  -0.30076745\n",
      "Mean:  0.012600201\n",
      "Var:  0.048503608\n",
      "Bias:  0.35802794\n",
      "Input:  0.55963117\n",
      "Mean:  0.03109063\n",
      "Var:  0.028275982\n",
      "Bias:  0.16394013\n",
      "Input:  0.6613902\n",
      "Mean:  -0.020289928\n",
      "Var:  0.005259482\n",
      "Bias:  0.0\n",
      "Input:  -0.32463884\n",
      "Mean:  -0.020254672\n",
      "Var:  0.009098567\n",
      "Bias:  0.0\n",
      "Input:  -0.32407475\n",
      "Mean:  0.021920957\n",
      "Var:  0.021751389\n",
      "Bias:  0.012252987\n",
      "Input:  0.3629883\n",
      "Mean:  -0.005927786\n",
      "Var:  0.04391606\n",
      "Bias:  -0.17640145\n",
      "Input:  -0.27124602\n",
      "Mean:  -0.008491937\n",
      "Var:  0.033437714\n",
      "Bias:  0.116479546\n",
      "Input:  -0.019391447\n",
      "Mean:  -0.040763106\n",
      "Var:  0.0069726896\n",
      "Bias:  0.0\n",
      "Input:  -0.6522097\n",
      "Mean:  -0.020944148\n",
      "Var:  0.03058224\n",
      "Bias:  -0.010676136\n",
      "Input:  -0.34578252\n",
      "Mean:  0.026200743\n",
      "Var:  0.036815017\n",
      "Bias:  -0.113313876\n",
      "Input:  0.305898\n",
      "Mean:  -0.0047682617\n",
      "Var:  0.027116137\n",
      "Bias:  -0.088636875\n",
      "Input:  -0.16492906\n",
      "Mean:  -0.020406168\n",
      "Var:  0.0074419943\n",
      "Bias:  0.0\n",
      "Input:  -0.3264987\n",
      "Mean:  0.007468827\n",
      "Var:  0.027344923\n",
      "Bias:  -0.06441719\n",
      "Input:  0.055084042\n",
      "Mean:  0.0022038613\n",
      "Var:  0.031558692\n",
      "Bias:  0.21582663\n",
      "Input:  0.2510884\n",
      "Mean:  -0.02824138\n",
      "Var:  0.005370674\n",
      "Bias:  0.009108469\n",
      "Input:  -0.4427536\n",
      "Mean:  0.028826267\n",
      "Var:  0.025727997\n",
      "Bias:  -0.14362504\n",
      "Input:  0.31759524\n",
      "Mean:  0.0074752234\n",
      "Var:  0.038717154\n",
      "Bias:  0.44430685\n",
      "Input:  0.5639104\n",
      "Mean:  0.0106261885\n",
      "Var:  0.017086016\n",
      "Bias:  -0.18728931\n",
      "Input:  -0.017270297\n",
      "Mean:  -0.016590923\n",
      "Var:  0.0074646985\n",
      "Bias:  -0.0032565412\n",
      "Input:  -0.2687113\n",
      "Mean:  -0.006840687\n",
      "Var:  0.028171945\n",
      "Bias:  0.06946228\n",
      "Input:  -0.03998871\n",
      "Mean:  -0.0017432868\n",
      "Var:  0.018928606\n",
      "Bias:  -0.103532776\n",
      "Input:  -0.13142537\n",
      "Mean:  -0.0020244196\n",
      "Var:  0.018116415\n",
      "Bias:  -0.12597078\n",
      "Input:  -0.1583615\n",
      "Mean:  -0.0071171615\n",
      "Var:  0.033717994\n",
      "Bias:  -0.13101421\n",
      "Input:  -0.2448888\n",
      "Mean:  0.031336114\n",
      "Var:  0.037391357\n",
      "Bias:  -0.06815172\n",
      "Input:  0.4332261\n",
      "Mean:  -0.0014526593\n",
      "Var:  0.024839543\n",
      "Bias:  0.17501402\n",
      "Input:  0.15177147\n",
      "Mean:  0.016926177\n",
      "Var:  0.041119296\n",
      "Bias:  0.05350046\n",
      "Input:  0.3243193\n",
      "Mean:  0.0095020905\n",
      "Var:  0.04886104\n",
      "Bias:  0.1416122\n",
      "Input:  0.29364565\n",
      "Mean:  0.009699028\n",
      "Var:  0.039800618\n",
      "Bias:  0.09963778\n",
      "Input:  0.25482222\n",
      "Mean:  -0.0076482184\n",
      "Var:  0.013449226\n",
      "Bias:  0.07951745\n",
      "Input:  -0.04285405\n",
      "Mean:  0.0073259715\n",
      "Var:  0.024383403\n",
      "Bias:  0.15351279\n",
      "Input:  0.27072835\n",
      "Mean:  0.04102689\n",
      "Var:  0.045188088\n",
      "Bias:  -0.0011266717\n",
      "Input:  0.6553036\n",
      "Mean:  -0.013184728\n",
      "Var:  0.008111667\n",
      "Bias:  0.0\n",
      "Input:  -0.21095565\n",
      "Mean:  -0.051451664\n",
      "Var:  0.008324029\n",
      "Bias:  0.0\n",
      "Input:  -0.82322663\n",
      "Mean:  0.00831686\n",
      "Var:  0.02213212\n",
      "Bias:  0.041885715\n",
      "Input:  0.17495547\n",
      "Mean:  -0.029024234\n",
      "Var:  0.0073670135\n",
      "Bias:  -0.00212459\n",
      "Input:  -0.46651232\n",
      "Mean:  0.0014591115\n",
      "Var:  0.019994285\n",
      "Bias:  0.11185914\n",
      "Input:  0.13520493\n",
      "Mean:  0.017710166\n",
      "Var:  0.014014121\n",
      "Bias:  0.009426513\n",
      "Input:  0.29278916\n",
      "Mean:  0.0075257337\n",
      "Var:  0.022155665\n",
      "Bias:  0.061803203\n",
      "Input:  0.18221495\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "    # Need to reconstruct the graph in DeepExplain context, using the same weights.\n",
    "    # With Keras this is very easy:\n",
    "    # 1. Get the input tensor to the original model\n",
    "    input_tensor = model.layers[0].input\n",
    "    \n",
    "    # 2. We now target the output of the last dense layer (pre-softmax)\n",
    "    # To do so, create a new model sharing the same layers untill the last dense (index -2)\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.layers[-2].output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "\n",
    "    \n",
    "    a_gradin = de.explain('grad*input', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('saliency', target_tensor * ys, input_tensor, xs)\n",
    "    a_intgrad = de.explain('intgrad', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions2 = de.explain('deeplift', target_tensor * ys, input_tensor, xs)\n",
    "    a_linear = de.explain('linear', target_tensor * ys, input_tensor, xs)\n",
    "    a_shap = de.explain('shapley', target_tensor * ys, input_tensor, xs)\n",
    "    \n",
    "    #attributions2 = de.explain('elrp', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('occlusion', target_tensor * ys, input_tensor, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute exacly shapley values!\n",
    "\n",
    "from deepexplain.tensorflow.exact_shapley import compute_shapley\n",
    "a_exact = compute_shapley(xs[0], lambda x: (fModel.predict(np.array([x]))*ys).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.27709099  11.27397213  15.58803604  -8.96465238  -6.87860627\n",
      "  -2.58886045  -1.26034162  -1.20018311  -1.4543505   -0.73936338\n",
      "  -1.74268701   4.51689602   6.21317845  14.13852986   9.97181662\n",
      "  -3.28548023]\n"
     ]
    }
   ],
   "source": [
    "print (a_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fdf0419ce80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/colors.py:823: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/ma/core.py:2784: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABnJJREFUeJzt3H+o7/ccwPHny64tP5bFjbl+LaL4QyuzGSJRCjUyWmRR\n/pgRRfGHxiYk+4fys/yh/IoWWfIvyab9oYkUoTab3xvz444hb3+c78nZmnsv1/Hd4fGo2/me+/l8\nvu/XOffc5/l8PqfvmbVWwP+3e217AGD7hAAQAkAIgIQASAiAhIBjmJkbZuY5256D/ScEB9jMXDQz\n183M0Zn55ebxpTMz+7DW5TPzyf/0897NOmfNzJqZQ/u9Fv8gBAfUzLypen91ZXVm9ZDqkupp1al3\ns/8p/9UBOVCE4ACamQdU76guXWtdtdb6/dpx/Vrr5WutO2bm4zPz4Zn58swcrZ41M8+fmetn5ncz\nc9PMXH6X533FzNw4M7fOzFuPM8OamUtm5gczc9vMfHD3TGRmXjkz18zMB2bmtzPzvZl59p5j73TJ\ncZezja9t3t42M3+YmfNP/jPG8QjBwXR+dVr1xePs97LqXdXp1dero9XF1RnV86vXzMwLq2bmCdWH\nq1dUR6oHVQ8/zvO/oHpy9cTqpdVz92w7r/pRdbh6e/X5mXngCXxsz9i8PWOtdf+11jdO4BhOkhAc\nTIerW9Zaf939i5m5dvOd+Y8zs/uf6YtrrWvWWn9ba/1prfXVtdZ3Nu9/u/pM9czNvhdWX1prfW2t\ndUd1WfW348zxnrXWbWutH1dfqc7es+2X1fvWWn9Za322+n478eEeSAgOplurw3tvqK21nrrWOmOz\nbfff9aa9B83MeTPzlZn51cz8tp17Coc3m4/s3X+tdXTzXMfy8z2Pb6/uv+f9n6w7v6Ltxs0a3AMJ\nwcH0jeqO6oLj7HfXl5Z+urq6esRa6wHVR6rdnzD8rHrE7o4zc992Lg/+XQ+7y08vHln9dPP4aHXf\nPdvOPMbM/BcIwQG01rqtuqL60MxcODOnz8y9Zubs6n7HOPT06tdrrT/NzLnt3EPYdVX1gpl5+syc\n2s7NyJP5+nhw9fqZuffMvKR6fPXlzbZvVRdttp3TzmXJrl+1c0ny6JNYm3+REBxQa633Vm+s3lz9\nYvPno9Vbqmv/yWGXVu+Ymd9Xb6s+t+f5vlu9tp2zhp9Vv6luPokRr6seW93Szg3LC9dau5cal1WP\n2axxxWbN3Tlu3+x/zeaex1NOYgZO0PjFJPynzcwrq1evtZ6+7Vk4Mc4IACEAXBoAOSMAqq29wuuH\nr7/of/JU5Asvfue2R9g3F5/90G2PsC8OfeLybY+wbx70uitP6JWozggAIQCEAEgIgIQASAiAhABI\nCICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiA\nhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQA\nqA5ta+H7XPGxbS29ry65+sptj7BvvvuoN2x7hH3xuFN8P/QZAIQAEAIgIQASAiAhABICICEAEgIg\nIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEA\nEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhAKpD\n21r4C2c9aVtL76sX3fDNbY+wb865+bptj7Av/nzkyLZH2DpnBIAQAEIAJARAQgAkBEBCACQEQEIA\nJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQE\nQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgBUh7a1\n8Luf98ZtLb2vXnXaKdseYd/cfOTcbY+wLx538ae2PcK++fMFJ7afMwJACAAhABICICEAEgIgIQAS\nAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIg\nIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEA\nEgKgmrXWtmcAtswZASAEgBAACQGQEAAJAZAQAAkBkBAACQGQEAAJAZAQAAkBkBAACQGQEAAJAZAQ\nAAkBkBAACQGQEADV3wEcORAoPG45hQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf044f7a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAiAhABICICEAqn8BJjnZ7ua+6+4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf06d13a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf0449fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABSlJREFUeJzt2k2opXUdwPHvL6cUZqKipAxCXLQwRGzTtDEkN5FtImgp\nBpWt2owLiRYmzVKCCkKE0GgjtSpx1UoyiVpIiBhhTBgWvcgMQtLL9d9irnDIhXeIM8/o/Xzgwjn3\nPC+/Z3G/9/+cc2atFXC8vW3rAYDtCQEgBIAQAAkBkBAACcGxNTO3zsxvt56DK8P4HsFb38ycq764\n1vrZ1rNwZbIi4LKamRNbz8DrCcExNTO3zcwfd56fm5l7ZuY3M3NhZh6dmWt2Xv/MzDw9M+dn5hcz\nc/POa/fOzPMz8/LMPDszn9157a6ZeXJmvjUzf6/uu1zXyNEJAbs+X32quqG6ubqramY+Wn2/urt6\nb/Vg9ZOZufpwv+erW6t3Vd+ofjgz1+0c93T1++r91dm9XwWXTAjY9e211otrrZeqn1a3HP7+y9WD\na61frrUO1lqPVP+sPl611vrR4X6vrrUerX5XfWznuC+utb6z1vrPWuuVy3g9HJEQsOvPO4//UZ06\nfHx9debwtuD8zJyvPlR9sGpm7ty5bThf3VS9b+dYL1yG2fk/eOOGo3ihOrvWet2yfmaurx6qbq+e\nWmsdzMzT1exs5qOpK5wVwfHx9pm55rWfLu2fwEPVV2bm9Fx0cmbumJl3Vie7+If+16qZ+UIXVwS8\niVgRHB+P/8/zJ4+641rr1zPzpeq71YerV6qfV0+stZ6dmQeqp6pXqx9cyrG5MvhCEeDWABACICEA\nEgKgDT81+NWnb39Lvkv53Dcf3nqEvfnAqavfeKM3oU8ePLf1CHtz1Y2fmDfeyooASAiAhABICICE\nAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABI\nCICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiA\nhABICICEAKhObHXij/z4sa1OvVfX3nf31iPszamvf2/rEfbi4Jm/bD3C3lx1xO2sCAAhAIQASAiA\nhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQA\nSAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgI\ngIQASAiAhABICIDqxFYnPnPyxq1OvVdf+9szW4+wN+++cG7rEfbiX386t/UIe/OOI25nRQAIASAE\nQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBC\nACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAkBEBCACQEQEIAJARAQgAk\nBEBCACQEQEIAJARAdWKrEz9+5/1bnXqvvvrvg61H2JuX33PD1iPsxS2PXbf1CHvzh88dbTsrAkAI\nACEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAh\nABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQASAiAhABICICEAEgIgIQAS\nAiAhABICICEAEgIgIQASAqCatdbWMwAbsyIAhAAQAiAhABICICEAEgIgIQASAiAhABICICEAEgIg\nIQASAiAhABICICEAEgIgIQASAiAhABICoPovBoylumBJgVMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf044a5780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXh+ZfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf0447c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDvqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf044594a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCICEAEgIgIQASAiAhACo/hcYMrnxA44X8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf041da358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf04145390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPIAAAD3CAYAAAAnpQkXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf04454b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot attributions\n",
    "from utils import plot, plt\n",
    "%matplotlib inline\n",
    "plot(a_gradin.reshape(img_rows, img_cols), xs.reshape(img_rows, img_cols)).title('GradInput')\n",
    "plt.figure()\n",
    "plot(a_intgrad.reshape(img_rows, img_cols), xs.reshape(img_rows, img_cols)).title('IntGrad')\n",
    "plt.figure()\n",
    "plot(a_res.reshape(img_rows, img_cols), xs.reshape(img_rows, img_cols)).title('DeepLift (Rescale)')\n",
    "plt.figure()\n",
    "plot((a_linear).reshape(img_rows, img_cols), xs.reshape(img_rows, img_cols)).title('Linear')\n",
    "plt.figure()\n",
    "plot(a_rc.reshape(img_rows, img_cols), xs.reshape(img_rows, img_cols)).title('DeepLift (RevCancel)')\n",
    "plt.figure()\n",
    "plot((a_shap).reshape(img_rows, img_cols), xs.reshape(img_rows, img_cols)).title('Deep Shap')\n",
    "plt.figure()\n",
    "\n",
    "plot((a_exact).reshape(img_rows, img_cols), xs.reshape(img_rows, img_cols)).title('Exact Shap')\n",
    "\n",
    "methods = [a_gradin, a_intgrad, a_res,a_linear, a_rc, a_shap, a_exact]\n",
    "confusion = np.zeros((len(methods), len(methods)))\n",
    "for i, m1 in enumerate(methods):\n",
    "    for j, m2 in enumerate(methods):\n",
    "        confusion[i][j] = ((m1-m2)**2).mean()\n",
    "plt.figure()\n",
    "plt.matshow(confusion, cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running robustness test...\n",
      "Storing robustness results...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from deepexplain.tensorflow.accuracy_robustness import run_robustness_test\n",
    "original_maps = [a_gradin, a_intgrad, a_res, a_linear, a_rc, a_shap, a_exact]\n",
    "names = ['GradInput', 'IntGrad', 'DeepLift (Recale)','Linear', 'DeepLift (RevCanc)', 'ApprShapley', 'Shapley']\n",
    "run_robustness_test(fModel, xs, ys, original_maps, names, 'Test', 1,\n",
    "                        result_path='.', mode='prediction', reduce_dim=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running delta test...\n",
      "Done\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepexplain.tensorflow.sensitivityn import run_sensitivity_test\n",
    "run_sensitivity_test(fModel, xs, ys, original_maps, names, 'Test',\n",
    "                        result_path='.', number_of_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
